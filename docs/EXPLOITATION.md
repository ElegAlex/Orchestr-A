# üìò Documentation d'Exploitation ‚Äî Orchestr'A V2

| Information | Valeur |
|---|---|
| **Version du document** | 1.0.0 |
| **Date de derni√®re mise √† jour** | 2026-02-06 |
| **Application** | Orchestr'A V2 |
| **Environnement** | Production ‚Äî Docker Compose sur RHEL 8.10 |
| **Pr√©requis** | Installation termin√©e (cf. `INSTALL-RHEL8.md`) |

## Tableau des r√©visions

| Version | Date | Auteur | Modifications |
|---|---|---|---|
| 1.0.0 | 2026-02-06 | √âquipe Orchestr'A | Cr√©ation initiale du document |

## Contacts et escalade

> ‚ö†Ô∏è **√Ä compl√©ter par l'√©quipe d'exploitation** avec les contacts r√©els.

| Niveau | R√¥le | P√©rim√®tre | Contact |
|---|---|---|---|
| N1 | Exploitant | Op√©rations courantes, monitoring, red√©marrage | _√Ä compl√©ter_ |
| N2 | Administrateur syst√®me | Infrastructure Docker, OS, r√©seau, s√©curit√© | _√Ä compl√©ter_ |
| N3 | D√©veloppeur / Tech Lead | Bugs applicatifs, migrations, √©volutions | _√Ä compl√©ter_ |
| N4 | Responsable projet | D√©cisions d'impact m√©tier, PRA | _√Ä compl√©ter_ |

---

## Table des mati√®res

- [0. Glossaire](#0-glossaire)
- [1. Pr√©sentation de l'application](#1-pr√©sentation-de-lapplication)
- [2. Architecture technique](#2-architecture-technique)
  - [2.1 Sch√©ma d'architecture](#21-sch√©ma-darchitecture)
  - [2.2 Inventaire des composants](#22-inventaire-des-composants)
  - [2.3 Arborescence des fichiers critiques](#23-arborescence-des-fichiers-critiques)
- [3. Op√©rations courantes](#3-op√©rations-courantes)
  - [3.1 D√©marrage / Arr√™t / Red√©marrage](#31-d√©marrage--arr√™t--red√©marrage)
  - [3.2 Consultation des logs](#32-consultation-des-logs)
  - [3.3 V√©rification de l'√©tat de sant√©](#33-v√©rification-de-l√©tat-de-sant√©)
  - [3.4 Gestion des utilisateurs applicatifs](#34-gestion-des-utilisateurs-applicatifs)
- [4. Mise √† jour de l'application](#4-mise-√†-jour-de-lapplication)
  - [4.1 Proc√©dure de mise √† jour standard](#41-proc√©dure-de-mise-√†-jour-standard)
  - [4.2 Rollback](#42-rollback)
  - [4.3 Mise √† jour des composants d'infrastructure](#43-mise-√†-jour-des-composants-dinfrastructure)
- [5. Sauvegarde et restauration](#5-sauvegarde-et-restauration)
  - [5.1 Strat√©gie de sauvegarde](#51-strat√©gie-de-sauvegarde)
  - [5.2 Backup base de donn√©es](#52-backup-base-de-donn√©es)
  - [5.3 Backup des fichiers de configuration](#53-backup-des-fichiers-de-configuration)
  - [5.4 Backup des volumes Docker](#54-backup-des-volumes-docker)
  - [5.5 Restauration](#55-restauration)
- [6. S√©curit√© op√©rationnelle](#6-s√©curit√©-op√©rationnelle)
  - [6.1 Gestion des secrets](#61-gestion-des-secrets)
  - [6.2 Certificats SSL](#62-certificats-ssl)
  - [6.3 S√©curit√© syst√®me](#63-s√©curit√©-syst√®me)
  - [6.4 Audit et tra√ßabilit√©](#64-audit-et-tra√ßabilit√©)
- [7. Monitoring et alerting](#7-monitoring-et-alerting)
  - [7.1 M√©triques √† surveiller](#71-m√©triques-√†-surveiller)
  - [7.2 Script de monitoring](#72-script-de-monitoring)
  - [7.3 Mise en place d'alertes](#73-mise-en-place-dalertes)
- [8. Fiches r√©flexes incidents](#8-fiches-r√©flexes-incidents)
- [9. Maintenance pr√©ventive](#9-maintenance-pr√©ventive)
  - [9.1 Planning de maintenance](#91-planning-de-maintenance)
  - [9.2 Nettoyage Docker](#92-nettoyage-docker)
  - [9.3 Maintenance PostgreSQL](#93-maintenance-postgresql)
  - [9.4 Maintenance Redis](#94-maintenance-redis)
- [10. Proc√©dures exceptionnelles](#10-proc√©dures-exceptionnelles)
  - [10.1 Migration vers un nouveau serveur](#101-migration-vers-un-nouveau-serveur)
  - [10.2 Changement de nom de domaine](#102-changement-de-nom-de-domaine)
  - [10.3 Mont√©e en charge](#103-mont√©e-en-charge)
- [11. Annexes](#11-annexes)
  - [A. Commandes Docker ‚Äî Aide-m√©moire](#a-commandes-docker--aide-m√©moire)
  - [B. R√©capitulatif des ports et flux](#b-r√©capitulatif-des-ports-et-flux)
  - [C. R√©capitulatif des volumes et donn√©es persistantes](#c-r√©capitulatif-des-volumes-et-donn√©es-persistantes)
  - [D. R√©capitulatif des fichiers de configuration](#d-r√©capitulatif-des-fichiers-de-configuration)
  - [E. Crontab de production recommand√©e](#e-crontab-de-production-recommand√©e)
  - [F. Templates de communication](#f-templates-de-communication)

---

## 0. Glossaire

| Terme | D√©finition |
|---|---|
| **API** | Application Programming Interface ‚Äî couche backend qui traite la logique m√©tier |
| **Certbot** | Outil automatis√© pour obtenir et renouveler les certificats SSL Let's Encrypt |
| **Container** | Instance isol√©e d'une image Docker, ex√©cutant un processus unique |
| **CORS** | Cross-Origin Resource Sharing ‚Äî m√©canisme de s√©curit√© contr√¥lant les requ√™tes entre domaines |
| **Docker Compose** | Outil d'orchestration pour d√©ployer une stack multi-containers |
| **Graceful shutdown** | Arr√™t propre d'un service permettant de terminer les requ√™tes en cours |
| **Health check** | V√©rification automatique de l'√©tat de sant√© d'un service |
| **HSTS** | HTTP Strict Transport Security ‚Äî force l'utilisation de HTTPS |
| **JWT** | JSON Web Token ‚Äî m√©canisme d'authentification sans √©tat (stateless) |
| **Let's Encrypt** | Autorit√© de certification gratuite et automatis√©e |
| **Nginx** | Serveur web / reverse proxy qui route le trafic vers les services internes |
| **PRA** | Plan de Reprise d'Activit√© ‚Äî proc√©dure de reconstruction apr√®s sinistre |
| **Prisma** | ORM (Object-Relational Mapping) utilis√© pour la gestion du sch√©ma et des migrations de base de donn√©es |
| **Redis** | Base de donn√©es en m√©moire utilis√©e comme cache et stockage de sessions |
| **Reverse proxy** | Serveur interm√©diaire qui re√ßoit les requ√™tes clients et les redirige vers les services internes |
| **RPO** | Recovery Point Objective ‚Äî perte de donn√©es maximale acceptable |
| **RTO** | Recovery Time Objective ‚Äî temps de restauration maximal acceptable |
| **SELinux** | Security-Enhanced Linux ‚Äî module de s√©curit√© du noyau Linux |
| **SLA** | Service Level Agreement ‚Äî engagement de niveau de service |
| **SSL/TLS** | Protocoles de chiffrement pour s√©curiser les communications r√©seau |
| **Stack** | Ensemble des services applicatifs d√©ploy√©s ensemble |
| **Volume** | Espace de stockage persistant g√©r√© par Docker |

---

## 1. Pr√©sentation de l'application

### Description fonctionnelle

**Orchestr'A V2** est une application web de gestion de projets et de ressources humaines destin√©e aux **collectivit√©s territoriales**. Elle offre une plateforme unifi√©e permettant de piloter les projets, g√©rer les t√¢ches, suivre le temps de travail, administrer les cong√©s, le t√©l√©travail et les comp√©tences des agents.

L'application repose sur une architecture web moderne compos√©e d'une API REST (NestJS/Fastify) et d'une interface utilisateur (Next.js), avec PostgreSQL pour la persistance des donn√©es et Redis pour le cache et les sessions.

Le mod√®le de donn√©es comprend 18 entit√©s couvrant : gestion des utilisateurs et des r√¥les (6 niveaux RBAC), organisation en d√©partements et services, projets avec epics/milestones/t√¢ches, matrice RACI, suivi du temps, cong√©s configurables, t√©l√©travail, comp√©tences, documents et commentaires.

### Criticit√© et engagements de service

| Indicateur | Valeur recommand√©e |
|---|---|
| **Disponibilit√© cible** | 99,5 % (hors maintenance planifi√©e) |
| **RTO** (temps de restauration) | ‚â§ 2 heures |
| **RPO** (perte de donn√©es max.) | ‚â§ 24 heures (avec backup quotidien) |
| **Fen√™tre de maintenance** | Samedi 22h ‚Äì Dimanche 6h |
| **D√©lai de notification** | 48h avant maintenance planifi√©e |

### Plages de maintenance recommand√©es

| Jour | Plage horaire | Type de maintenance |
|---|---|---|
| Samedi 22h ‚Äì Dimanche 6h | Principale | Mises √† jour majeures, migrations |
| Jours ouvr√©s 12h ‚Äì 14h | Secondaire | Interventions mineures (< 15 min) |

---

## 2. Architecture technique

### 2.1 Sch√©ma d'architecture

```
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ           INTERNET                  ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                        ‚îÇ
                                   Port 80/443
                                        ‚îÇ
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ     orchestr-a-nginx-prod           ‚îÇ
                         ‚îÇ     Nginx 1.27-alpine               ‚îÇ
                         ‚îÇ     (Reverse Proxy + SSL)           ‚îÇ
                         ‚îÇ                                     ‚îÇ
                         ‚îÇ  :80 ‚Üí redirect HTTPS               ‚îÇ
                         ‚îÇ  :443 ‚Üí SSL termination             ‚îÇ
                         ‚îÇ  /.well-known ‚Üí certbot challenge   ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ                ‚îÇ
                         /api/*   ‚îÇ                ‚îÇ  /*
                                  ‚îÇ                ‚îÇ
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ orchestr-a-     ‚îÇ    ‚îÇ orchestr-a-          ‚îÇ
                   ‚îÇ api-prod        ‚îÇ    ‚îÇ web-prod             ‚îÇ
                   ‚îÇ NestJS/Fastify  ‚îÇ    ‚îÇ Next.js 16           ‚îÇ
                   ‚îÇ :4000 (interne) ‚îÇ    ‚îÇ :3000 (interne)      ‚îÇ
                   ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ          ‚îÇ
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ orchestr ‚îÇ  ‚îÇ orchestr-a-    ‚îÇ
               ‚îÇ -a-      ‚îÇ  ‚îÇ redis-prod     ‚îÇ
               ‚îÇ postgres ‚îÇ  ‚îÇ Redis 7.4      ‚îÇ
               ‚îÇ -prod    ‚îÇ  ‚îÇ :6379 (interne)‚îÇ
               ‚îÇ PG 18    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ :5432    ‚îÇ
               ‚îÇ(interne) ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ orchestr-a-          ‚îÇ
                               ‚îÇ certbot-prod         ‚îÇ
                               ‚îÇ Renouvellement SSL   ‚îÇ
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ (toutes les 12h)     ‚îÇ
  ‚îÇ Volumes persistants :      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚îÇ
  ‚îÇ  üì¶ orchestr-a-postgres-data-prod  (donn√©es PG)
  ‚îÇ  üì¶ orchestr-a-redis-data-prod     (donn√©es Redis AOF)
  ‚îÇ  üì¶ orchestr-a-api-logs-prod       (logs API)
  ‚îÇ  üì¶ orchestr-a-nginx-logs-prod     (logs Nginx)
  ‚îÇ  üì¶ orchestr-a-certbot-certs       (certificats SSL)
  ‚îÇ  üì¶ orchestr-a-certbot-www         (challenge ACME)
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
```

**R√©seau Docker** : `orchestr-a-network-prod` (bridge) ‚Äî tous les containers communiquent sur ce r√©seau interne. Seuls les ports 80 et 443 de Nginx sont expos√©s √† l'ext√©rieur.

### 2.2 Inventaire des composants

#### Tableau des containers

| Container | Image | Port interne | Port expos√© | Volume(s) | D√©pendances | Health check | Criticit√© |
|---|---|---|---|---|---|---|---|
| `orchestr-a-postgres-prod` | `postgres:18-alpine` | 5432 | Aucun | `postgres_data_prod` | Aucune | `pg_isready` (10s) | üî¥ Critique |
| `orchestr-a-redis-prod` | `redis:7.4-alpine` | 6379 | Aucun | `redis_data_prod` | Aucune | `redis-cli ping` (10s) | üü° Important |
| `orchestr-a-api-prod` | Build local (`apps/api/Dockerfile`) | 4000 | Aucun | `api_logs_prod` | PostgreSQL ‚úÖ, Redis ‚úÖ | `wget /api/health` (30s, start 90s) | üî¥ Critique |
| `orchestr-a-web-prod` | Build local (`apps/web/Dockerfile`) | 3000 | Aucun | Aucun | API ‚úÖ | `wget /` (30s, start 60s) | üü° Important |
| `orchestr-a-nginx-prod` | `nginx:1.27-alpine` | 80, 443 | `${HTTP_PORT:-80}`, `${HTTPS_PORT:-443}` | `certbot_certs`, `certbot_www`, `nginx_logs_prod`, `nginx.conf` (bind) | API ‚úÖ, Web ‚úÖ | `nginx -t` (30s) | üî¥ Critique |
| `orchestr-a-certbot-prod` | `certbot/certbot:latest` | Aucun | Aucun | `certbot_certs`, `certbot_www` | Aucune | Aucun | üü¢ Auxiliaire |

> üí° La notation "‚úÖ" dans les d√©pendances signifie que le service attend que le health check soit `healthy` avant de d√©marrer.

#### Ordre de d√©marrage (impos√© par `depends_on` + `service_healthy`)

```
1. PostgreSQL ‚îÄ‚îÄ‚îê
                ‚îú‚îÄ‚îÄ‚ñ∫ 3. API ‚îÄ‚îÄ‚ñ∫ 4. Web ‚îÄ‚îÄ‚ñ∫ 5. Nginx
2. Redis ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     6. Certbot (ind√©pendant, d√©marre en parall√®le)
```

#### Limites de ressources (configur√©es dans `docker-compose.prod.yml`)

| Container | CPU max | RAM max | CPU r√©serv√© | RAM r√©serv√©e |
|---|---|---|---|---|
| PostgreSQL | 2 | 2 Go | 0.5 | 512 Mo |
| Redis | 1 | 512 Mo | 0.25 | 128 Mo |
| API | 2 | 1 Go | 0.5 | 256 Mo |
| Web | 1 | 512 Mo | 0.25 | 128 Mo |
| Nginx | 0.5 | 256 Mo | 0.1 | 64 Mo |

**Total r√©serv√©** : 1.6 CPU / 1088 Mo RAM ‚Äî **Total max** : 6.5 CPU / 4352 Mo RAM

#### Matrice des flux r√©seau

| Source | Destination | Port | Protocole | Description |
|---|---|---|---|---|
| Internet | Nginx | 80 | HTTP | Redirection vers HTTPS |
| Internet | Nginx | 443 | HTTPS | Point d'entr√©e principal |
| Nginx | API | 4000 | HTTP | Requ√™tes `/api/*` |
| Nginx | Web | 3000 | HTTP | Requ√™tes `/` (frontend) |
| API | PostgreSQL | 5432 | TCP | Requ√™tes SQL |
| API | Redis | 6379 | TCP | Cache et sessions |
| Certbot | Let's Encrypt | 443 | HTTPS | Renouvellement certificats |

### 2.3 Arborescence des fichiers critiques

> Le r√©pertoire d'installation est `/opt/ORCHESTRA` (convention document√©e dans `INSTALL-RHEL8.md`).

| Chemin | Description | Criticit√© |
|---|---|---|
| `.env.production` | Secrets et configuration (DB password, Redis password, JWT secret) | üî¥ Ne pas toucher sans backup ‚Äî contient les secrets |
| `docker-compose.prod.yml` | D√©finition de la stack de production | üî¥ Ne pas modifier sans validation |
| `nginx/nginx.conf` | Configuration du reverse proxy, SSL, rate limiting | üî¥ Modifier avec pr√©caution ‚Äî tester avec `nginx -t` |
| `infrastructure/docker/postgres/init.sql` | Script d'initialisation PostgreSQL (extension uuid-ossp) | üü° Ex√©cut√© uniquement √† la premi√®re cr√©ation de la DB |
| `packages/database/prisma/schema.prisma` | Sch√©ma de base de donn√©es (source de v√©rit√©) | üî¥ Ne jamais modifier en production |
| `apps/api/Dockerfile` | Build de l'image API | üü° Modifiable ‚Äî rebuild n√©cessaire |
| `apps/web/Dockerfile` | Build de l'image Web | üü° Modifiable ‚Äî rebuild n√©cessaire |
| `scripts/backup-database.sh` | Script de sauvegarde PostgreSQL | üü¢ Utilisable librement |
| `scripts/restore-database.sh` | Script de restauration PostgreSQL | üü° Utilisation avec pr√©caution |
| `scripts/health-check.sh` | Script de v√©rification de sant√© | üü¢ Utilisable librement |
| `scripts/init-env.sh` | G√©n√©ration du fichier `.env.production` | üü° Ne pas relancer en production sans backup |

#### Permissions attendues

```bash
# Fichiers sensibles ‚Äî lecture seule pour le propri√©taire
chmod 600 /opt/ORCHESTRA/.env.production

# Scripts ‚Äî ex√©cutables
chmod 755 /opt/ORCHESTRA/scripts/*.sh

# Configuration Nginx ‚Äî lecture seule
chmod 644 /opt/ORCHESTRA/nginx/nginx.conf

# R√©pertoire backups ‚Äî accessible par l'utilisateur orchestr-a
chmod 750 /opt/ORCHESTRA/backups/
```

#### Emplacement des donn√©es

| Type | Emplacement | Description |
|---|---|---|
| Donn√©es PostgreSQL | Volume `orchestr-a-postgres-data-prod` | Donn√©es applicatives principales |
| Donn√©es Redis | Volume `orchestr-a-redis-data-prod` | Cache, sessions (AOF activ√©) |
| Logs API | Volume `orchestr-a-api-logs-prod` | Logs applicatifs NestJS |
| Logs Nginx | Volume `orchestr-a-nginx-logs-prod` | access.log et error.log |
| Certificats SSL | Volume `orchestr-a-certbot-certs` | Certificats Let's Encrypt |
| Backups DB | `/opt/ORCHESTRA/backups/` | Fichiers `.sql.gz` compress√©s |

---

## 3. Op√©rations courantes

> üí° **Alias recommand√©** ‚Äî Ajouter dans `~/.bashrc` pour simplifier les commandes :
> ```bash
> alias dc='docker compose --env-file .env.production -f docker-compose.prod.yml'
> ```
> Toutes les commandes de cette section utilisent cet alias. Sans alias, remplacer `dc` par la commande compl√®te.

### 3.1 D√©marrage / Arr√™t / Red√©marrage

#### D√©marrage complet de la stack

‚è±Ô∏è Temps estim√© : 2-4 minutes (inclut les health checks et les migrations Prisma)

```bash
# 1. Se placer dans le r√©pertoire du projet
cd /opt/ORCHESTRA

# 2. D√©marrer tous les services
dc up -d

# 3. Suivre le d√©marrage en temps r√©el
dc logs -f
# (Ctrl+C pour quitter le suivi sans arr√™ter les services)

# 4. V√©rifier que tous les containers sont "healthy"
dc ps
```

> üí° L'API a un `start_period` de 90 secondes pour permettre l'ex√©cution des migrations Prisma au premier d√©marrage. Ne pas s'inqui√©ter si le statut est `health: starting` pendant ce d√©lai.

#### Arr√™t propre (graceful shutdown)

‚è±Ô∏è Temps estim√© : 30-60 secondes

```bash
# Arr√™t propre ‚Äî les containers terminent les requ√™tes en cours
dc down
```

> üü° `docker compose down` arr√™te et **supprime** les containers, mais **conserve** les volumes. Les donn√©es sont pr√©serv√©es.

#### Arr√™t d'urgence

‚è±Ô∏è Temps estim√© : 5-10 secondes

```bash
# Arr√™t imm√©diat sans attendre la fin des requ√™tes
dc kill

# Puis nettoyage des containers arr√™t√©s
dc down
```

> üî¥ **√Ä n'utiliser qu'en cas d'urgence** ‚Äî les requ√™tes en cours seront interrompues, ce qui peut entra√Æner des transactions incompl√®tes en base de donn√©es.

#### Red√©marrage complet

‚è±Ô∏è Temps estim√© : 3-5 minutes

```bash
# Red√©marrage complet (arr√™t + d√©marrage)
dc down && dc up -d

# V√©rifier le statut
dc ps
```

#### Red√©marrage d'un service individuel

‚è±Ô∏è Temps estim√© : 30 secondes √† 2 minutes selon le service

```bash
# Red√©marrer uniquement l'API (sans impacter les autres services)
dc restart api

# Red√©marrer uniquement le frontend
dc restart web

# Red√©marrer Nginx (recharge la configuration)
dc restart nginx

# Red√©marrer Redis (‚ö†Ô∏è les sessions en cours seront perdues)
dc restart redis

# Red√©marrer PostgreSQL (üî¥ interrompt TOUTES les requ√™tes en cours)
dc restart postgres
```

> ‚ö†Ô∏è **Ordre de red√©marrage recommand√©** si plusieurs services doivent √™tre red√©marr√©s :
> 1. PostgreSQL, 2. Redis, 3. API, 4. Web, 5. Nginx
>
> Cet ordre respecte les d√©pendances entre services.

#### V√©rifications post-op√©ration

Apr√®s tout d√©marrage ou red√©marrage, ex√©cuter :

```bash
# 1. V√©rifier que tous les containers sont "Up" et "healthy"
dc ps

# 2. Tester l'acc√®s √† l'application
curl -sSf http://localhost/api/health && echo " ‚úÖ API OK"
curl -sSf -o /dev/null http://localhost && echo " ‚úÖ Frontend OK"

# 3. V√©rifier les logs pour erreurs r√©centes
dc logs --tail=20 api | grep -i error
dc logs --tail=20 web | grep -i error
```

### 3.2 Consultation des logs

#### Logs temps r√©el

```bash
# Tous les services (flux combin√©, color√© par service)
dc logs -f

# Un service sp√©cifique
dc logs -f api          # API NestJS
dc logs -f web          # Frontend Next.js
dc logs -f postgres     # Base de donn√©es
dc logs -f redis        # Cache Redis
dc logs -f nginx        # Reverse proxy
dc logs -f certbot      # Renouvellement SSL
```

#### Logs historiques

```bash
# Derni√®res 100 lignes d'un service
dc logs --tail=100 api

# Logs depuis une date/heure sp√©cifique
dc logs --since="2026-02-06T10:00:00" api

# Logs des derni√®res 2 heures
dc logs --since=2h api

# Rechercher un pattern dans les logs
dc logs api 2>&1 | grep -i "error"
dc logs api 2>&1 | grep "500"
```

#### Filtrage par niveau de log

```bash
# Erreurs uniquement (API NestJS)
dc logs api 2>&1 | grep -iE "(error|exception|fatal)"

# Avertissements et erreurs
dc logs api 2>&1 | grep -iE "(warn|error|exception)"

# Logs d'acc√®s Nginx (requ√™tes HTTP)
dc logs nginx 2>&1 | grep -v "health"  # Exclure les health checks
```

#### Emplacement des fichiers de logs sur le filesystem

| Service | Volume Docker | Chemin dans le container | Fichiers |
|---|---|---|---|
| API | `orchestr-a-api-logs-prod` | `/app/logs/` | Logs applicatifs |
| Nginx (access) | `orchestr-a-nginx-logs-prod` | `/var/log/nginx/access.log` | Requ√™tes HTTP |
| Nginx (error) | `orchestr-a-nginx-logs-prod` | `/var/log/nginx/error.log` | Erreurs Nginx |

Pour acc√©der directement aux fichiers de logs sur l'h√¥te :

```bash
# Trouver le point de montage d'un volume
docker volume inspect orchestr-a-nginx-logs-prod --format '{{ .Mountpoint }}'

# Lire les logs Nginx directement
sudo cat $(docker volume inspect orchestr-a-nginx-logs-prod --format '{{ .Mountpoint }}')/access.log
```

#### Rotation des logs

La rotation est g√©r√©e par le driver de logging Docker (configur√© dans `docker-compose.prod.yml`) :

| Service | Taille max par fichier | Nombre de fichiers | R√©tention totale |
|---|---|---|---|
| PostgreSQL | 50 Mo | 5 | 250 Mo |
| Redis | 10 Mo | 3 | 30 Mo |
| API | 50 Mo | 5 | 250 Mo |
| Web | 20 Mo | 3 | 60 Mo |
| Nginx | 20 Mo | 5 | 100 Mo |

> üí° La rotation est automatique. Aucune configuration suppl√©mentaire n'est n√©cessaire.

### 3.3 V√©rification de l'√©tat de sant√©

#### Health check rapide

```bash
# Statut de tous les containers (√©tat + health)
dc ps
```

R√©sultat attendu ‚Äî tous les services doivent √™tre `Up` et `(healthy)` :

```
NAME                       STATUS                 PORTS
orchestr-a-postgres-prod   Up X minutes (healthy)
orchestr-a-redis-prod      Up X minutes (healthy)
orchestr-a-api-prod        Up X minutes (healthy)
orchestr-a-web-prod        Up X minutes (healthy)
orchestr-a-nginx-prod      Up X minutes (healthy)
orchestr-a-certbot-prod    Up X minutes
```

#### Commandes de health check manuelles

```bash
# PostgreSQL ‚Äî v√©rifier que le serveur accepte les connexions
docker exec orchestr-a-postgres-prod pg_isready -U postgres -d orchestr_a_prod
# Attendu : "/var/run/postgresql:5432 - accepting connections"

# Redis ‚Äî v√©rifier la r√©ponse PONG
docker exec orchestr-a-redis-prod redis-cli -a "$REDIS_PASSWORD" ping
# Attendu : "PONG"

# API ‚Äî v√©rifier l'endpoint de sant√©
curl -sf http://localhost/api/health
# Attendu : r√©ponse JSON avec status "ok"

# Frontend ‚Äî v√©rifier l'acc√®s √† la page d'accueil
curl -sf -o /dev/null -w "%{http_code}" http://localhost
# Attendu : "200"

# Nginx ‚Äî v√©rifier la configuration
docker exec orchestr-a-nginx-prod nginx -t
# Attendu : "syntax is ok" et "test is successful"
```

#### Utilisation du script `health-check.sh`

Le script `scripts/health-check.sh` effectue une v√©rification compl√®te et automatis√©e :

```bash
cd /opt/ORCHESTRA
./scripts/health-check.sh
```

Ce script v√©rifie :
1. **√âtat des 5 containers** ‚Äî running + Docker health status
2. **Endpoints HTTP** ‚Äî API health, frontend via Nginx, frontend direct
3. **Connectivit√© base de donn√©es** ‚Äî connexion PostgreSQL + comptage des enregistrements (users, projects, tasks)
4. **Ressources Docker** ‚Äî espace disque (`docker system df`) et consommation CPU/RAM (`docker stats`)

Code de retour : `0` = tout OK, `1` = erreurs d√©tect√©es (le nombre d'erreurs est affich√©).

#### V√©rifications syst√®me

```bash
# Espace disque de la VM
df -h /

# Espace disque Docker (images, containers, volumes)
docker system df

# M√©moire disponible
free -h

# Charge CPU
uptime

# Espace disque des volumes Docker (d√©tail)
docker system df -v | grep -A 50 "VOLUME NAME"
```

#### üìã Checklist de v√©rification quotidienne

| # | V√©rification | Commande | R√©sultat attendu | Fr√©quence |
|---|---|---|---|---|
| 1 | Containers actifs | `dc ps` | Tous `Up (healthy)` | Quotidien |
| 2 | API op√©rationnelle | `curl -sf http://localhost/api/health` | R√©ponse JSON | Quotidien |
| 3 | Frontend accessible | `curl -sf -o /dev/null http://localhost` | HTTP 200 | Quotidien |
| 4 | Espace disque | `df -h / \| awk 'NR==2{print $5}'` | < 80 % | Quotidien |
| 5 | M√©moire disponible | `free -h \| awk '/Mem/{print $4}'` | > 1 Go | Quotidien |
| 6 | Logs d'erreurs | `dc logs --since=24h api 2>&1 \| grep -c -i error` | 0 ou minimal | Quotidien |
| 7 | Backup r√©cent | `ls -lt backups/ \| head -2` | Fichier < 24h | Quotidien |
| 8 | Certificat SSL | `echo \| openssl s_client -connect localhost:443 2>/dev/null \| openssl x509 -noout -dates` | > 30 jours | Hebdomadaire |

### 3.4 Gestion des utilisateurs applicatifs

#### Identifiants par d√©faut

Apr√®s l'installation initiale, un compte administrateur est cr√©√© automatiquement par le seed Prisma :

| Champ | Valeur |
|---|---|
| **Login** | `admin` |
| **Mot de passe** | `admin123` |
| **Email** | `admin@orchestr-a.internal` |
| **R√¥le** | `ADMIN` |

> üî¥ **S√âCURIT√â** ‚Äî Changer imm√©diatement le mot de passe admin apr√®s la premi√®re connexion.

> ‚ö†Ô∏è L'authentification utilise le champ **`login`** (et non l'email). Saisir `admin` dans le champ identifiant, pas `admin@orchestr-a.internal`.

#### R√©initialisation du mot de passe admin

Si le mot de passe admin est perdu, le r√©initialiser directement en base de donn√©es :

‚è±Ô∏è Temps estim√© : 5 minutes

```bash
# 1. G√©n√©rer un hash bcrypt pour le nouveau mot de passe
#    (remplacer "NouveauMotDePasse123!" par le mot de passe souhait√©)
docker exec orchestr-a-api-prod node -e "
const bcrypt = require('bcrypt');
bcrypt.hash('NouveauMotDePasse123!', 10).then(h => console.log(h));
"

# 2. Copier le hash affich√©, puis mettre √† jour en base
docker exec orchestr-a-postgres-prod psql -U postgres -d orchestr_a_prod -c "
UPDATE users SET \"passwordHash\" = '<hash_copi√©_ici>' WHERE login = 'admin';
"

# 3. V√©rifier la modification
docker exec orchestr-a-postgres-prod psql -U postgres -d orchestr_a_prod -c "
SELECT login, email, role FROM users WHERE login = 'admin';
"
```

#### R√¥les disponibles (RBAC)

L'application d√©finit 6 r√¥les avec des permissions hi√©rarchiques :

| R√¥le | Description | P√©rim√®tre |
|---|---|---|
| `ADMIN` | Administrateur syst√®me | Acc√®s total : configuration, utilisateurs, tous les projets |
| `RESPONSABLE` | Responsable de d√©partement | Gestion de son d√©partement, validation des cong√©s |
| `MANAGER` | Chef de projet | Gestion de ses projets, affectation des t√¢ches |
| `REFERENT_TECHNIQUE` | R√©f√©rent technique | Expertise technique, validation technique des t√¢ches |
| `CONTRIBUTEUR` | Contributeur (r√¥le par d√©faut) | Travail sur les t√¢ches assign√©es, saisie du temps |
| `OBSERVATEUR` | Observateur | Consultation seule, aucune modification |

#### Cr√©ation d'utilisateurs

La cr√©ation d'utilisateurs se fait via l'interface web par un administrateur :
1. Se connecter avec un compte `ADMIN`
2. Acc√©der √† la gestion des utilisateurs
3. Cr√©er un nouvel utilisateur (login, email, nom, pr√©nom, r√¥le, d√©partement)

---

## 4. Mise √† jour de l'application

### 4.1 Proc√©dure de mise √† jour standard

‚è±Ô∏è Temps estim√© : 10-20 minutes | ‚è±Ô∏è Indisponibilit√© : 3-5 minutes

> üìã **Checklist pr√©-mise √† jour** :
> - [ ] Backup base de donn√©es effectu√©
> - [ ] Fen√™tre de maintenance communiqu√©e aux utilisateurs
> - [ ] Acc√®s SSH au serveur v√©rifi√©
> - [ ] Images Docker pr√©c√©dentes identifi√©es (pour rollback)

#### √âtapes

```bash
cd /opt/ORCHESTRA
```

**1. Sauvegarder la base de donn√©es** (point de rollback n¬∞1)

```bash
./scripts/backup-database.sh
# V√©rifier que le fichier a √©t√© cr√©√©
ls -la backups/ | head -3
```

**2. Noter les images Docker actuelles** (point de rollback n¬∞2)

```bash
# Sauvegarder les IDs des images actuelles pour rollback √©ventuel
docker images --format "{{.Repository}}:{{.Tag}} {{.ID}}" | grep orchestr > /tmp/docker-images-before-update.txt
cat /tmp/docker-images-before-update.txt
```

**3. R√©cup√©rer les nouvelles sources**

```bash
git fetch origin
git pull origin master
```

**4. V√©rifier les changements**

```bash
# V√©rifier s'il y a des modifications de sch√©ma Prisma (migration n√©cessaire)
git log --oneline --name-only HEAD@{1}..HEAD -- packages/database/prisma/

# V√©rifier s'il y a des changements dans docker-compose ou les Dockerfiles
git log --oneline --name-only HEAD@{1}..HEAD -- docker-compose.prod.yml apps/*/Dockerfile nginx/
```

**5. Reconstruire les images Docker**

```bash
dc build --no-cache
```

> üí° Le `--no-cache` force la reconstruction compl√®te. Pour une mise √† jour rapide sans modification de d√©pendances, omettre ce flag.

**6. Red√©marrer les services** (d√©but de l'indisponibilit√©)

```bash
dc down && dc up -d
```

**7. Suivre le d√©marrage et les migrations**

```bash
# Les migrations Prisma sont ex√©cut√©es automatiquement par l'entrypoint de l'API
dc logs -f api
# Attendre le message "Application is listening on port 4000" ou similaire
# Ctrl+C pour quitter le suivi
```

**8. V√©rifier le bon fonctionnement** (fin de l'indisponibilit√©)

```bash
# Attendre que tous les services soient healthy
dc ps

# Tester l'API
curl -sf http://localhost/api/health && echo " ‚úÖ API OK"

# Tester le frontend
curl -sf -o /dev/null -w "%{http_code}" http://localhost && echo " ‚úÖ Frontend OK"

# V√©rifier les logs pour erreurs
dc logs --tail=50 api 2>&1 | grep -i error
```

**9. Tester fonctionnellement**

- Se connecter √† l'interface web
- V√©rifier les fonctionnalit√©s principales (projets, t√¢ches, cong√©s)

> ‚úÖ Si tout est OK, la mise √† jour est termin√©e. Nettoyer les anciennes images :
> ```bash
> docker image prune -f
> ```

### 4.2 Rollback

#### Rollback des images Docker (si l'application ne fonctionne plus)

‚è±Ô∏è Temps estim√© : 5-10 minutes

```bash
# 1. Arr√™ter les services
dc down

# 2. Consulter les images pr√©c√©dentes sauvegard√©es
cat /tmp/docker-images-before-update.txt

# 3. Revenir au commit Git pr√©c√©dent
git log --oneline -5  # Identifier le commit pr√©c√©dent
git checkout <commit_precedent>

# 4. Reconstruire avec les anciennes sources
dc build

# 5. Red√©marrer
dc up -d

# 6. V√©rifier
dc ps
curl -sf http://localhost/api/health
```

#### Rollback de migration Prisma

> ‚ö†Ô∏è **Prisma ne supporte pas nativement le rollback de migrations en production.** La commande `prisma migrate reset` **d√©truit toutes les donn√©es** et ne doit JAMAIS √™tre utilis√©e en production.

**Alternative en cas de migration probl√©matique :**

```bash
# 1. Restaurer le backup de la base de donn√©es
./scripts/restore-database.sh backups/orchestr-a-backup-<DATE>.sql.gz

# 2. Revenir au code pr√©c√©dent (avant la migration)
git checkout <commit_precedent>

# 3. Reconstruire et red√©marrer
dc build && dc down && dc up -d
```

### 4.3 Mise √† jour des composants d'infrastructure

#### Mise √† jour de Docker CE

‚è±Ô∏è Temps estim√© : 10-15 minutes | ‚è±Ô∏è Indisponibilit√© : 5-10 minutes

```bash
# 1. Sauvegarder la base avant toute intervention
cd /opt/ORCHESTRA && ./scripts/backup-database.sh

# 2. Arr√™ter la stack applicative
dc down

# 3. Mettre √† jour Docker
sudo dnf update docker-ce docker-ce-cli containerd.io docker-compose-plugin -y

# 4. Red√©marrer le service Docker
sudo systemctl restart docker

# 5. V√©rifier la version
docker --version
docker compose version

# 6. Red√©marrer la stack
dc up -d && dc ps
```

#### Mise √† jour de s√©curit√© RHEL

‚è±Ô∏è Temps estim√© : 15-30 minutes (peut n√©cessiter un reboot)

```bash
# 1. V√©rifier les mises √† jour de s√©curit√© disponibles
sudo dnf check-update --security

# 2. Sauvegarder avant intervention
cd /opt/ORCHESTRA && ./scripts/backup-database.sh

# 3. Appliquer les mises √† jour de s√©curit√© uniquement
sudo dnf update --security -y

# 4. V√©rifier si un reboot est n√©cessaire
sudo needs-restarting -r
# Si le code de retour est 1, un reboot est n√©cessaire

# 5. Si reboot n√©cessaire :
dc down                    # Arr√™ter la stack
sudo reboot                # Red√©marrer le serveur

# 6. Apr√®s reboot, v√©rifier et red√©marrer la stack
sudo systemctl status docker
cd /opt/ORCHESTRA && dc up -d && dc ps
```

#### Renouvellement des certificats SSL

Le renouvellement est **automatique** gr√¢ce au container `orchestr-a-certbot-prod` qui ex√©cute `certbot renew` toutes les 12 heures. Pour forcer un renouvellement manuel :

```bash
# Forcer le renouvellement
docker exec orchestr-a-certbot-prod certbot renew --force-renewal

# Recharger Nginx pour prendre en compte le nouveau certificat
docker exec orchestr-a-nginx-prod nginx -s reload
```

#### Mise √† jour des images de base (PostgreSQL, Redis, Nginx)

> ‚ö†Ô∏è **Op√©ration sensible** ‚Äî les mises √† jour mineures (ex: 18.1 ‚Üí 18.2) sont g√©n√©ralement s√ªres. Les mises √† jour majeures n√©cessitent une proc√©dure de migration sp√©cifique.

```bash
# 1. Backup complet
cd /opt/ORCHESTRA && ./scripts/backup-database.sh

# 2. Pull des nouvelles images
docker pull postgres:18-alpine
docker pull redis:7.4-alpine
docker pull nginx:1.27-alpine

# 3. Red√©marrer la stack (les nouvelles images seront utilis√©es)
dc down && dc up -d

# 4. V√©rifier
dc ps
```

---

## 5. Sauvegarde et restauration

### 5.1 Strat√©gie de sauvegarde

#### Objectifs

| Indicateur | Valeur | Signification |
|---|---|---|
| **RPO** | 24 heures | Perte maximale : les donn√©es de la derni√®re journ√©e |
| **RTO** | 2 heures | L'application doit √™tre restaur√©e en moins de 2 heures |

#### Ce qui DOIT √™tre sauvegard√©

| √âl√©ment | M√©thode | Fr√©quence | R√©tention | Criticit√© |
|---|---|---|---|---|
| Base de donn√©es PostgreSQL | `pg_dump` via `backup-database.sh` | Quotidienne (2h du matin) | 30 jours | üî¥ Critique |
| Fichier `.env.production` | Copie manuelle s√©curis√©e | √Ä chaque modification | Permanent | üî¥ Critique |
| Configuration Nginx | `nginx/nginx.conf` (versionn√© dans git) | Via git | Historique git | üü° Important |
| Certificats SSL | Volume `orchestr-a-certbot-certs` | Mensuelle | 3 mois | üü° Important |
| `docker-compose.prod.yml` | Versionn√© dans git | Via git | Historique git | üü° Important |

#### Ce qui N'A PAS besoin d'√™tre sauvegard√©

| √âl√©ment | Raison |
|---|---|
| Volume `orchestr-a-redis-data-prod` | Cache/sessions ‚Äî reconstruit automatiquement. Perte = d√©connexion des utilisateurs, pas de perte de donn√©es |
| Volume `orchestr-a-api-logs-prod` | Logs op√©rationnels ‚Äî utiles pour le diagnostic mais non critiques |
| Volume `orchestr-a-nginx-logs-prod` | Logs d'acc√®s ‚Äî non critiques |
| Volume `orchestr-a-certbot-www` | Fichiers de challenge ACME temporaires |
| Images Docker | Reconstruites √† partir des sources (git) |

### 5.2 Backup base de donn√©es

#### Proc√©dure manuelle

```bash
# Backup simple (non compress√©)
docker exec orchestr-a-postgres-prod pg_dump -U postgres orchestr_a_prod > backup-manual.sql

# Backup compress√©
docker exec orchestr-a-postgres-prod pg_dump -U postgres orchestr_a_prod | gzip > backup-manual-$(date +%Y%m%d_%H%M%S).sql.gz
```

#### Utilisation du script `backup-database.sh`

‚è±Ô∏è Temps estim√© : 1-5 minutes selon la taille de la base

```bash
cd /opt/ORCHESTRA
./scripts/backup-database.sh
```

Le script effectue automatiquement :
1. Cr√©e le r√©pertoire `./backups/` s'il n'existe pas
2. Ex√©cute `pg_dump` via le container `orchestr-a-postgres-prod` (utilisateur `postgres`, base `orchestr_a_prod`)
3. V√©rifie que le fichier a √©t√© cr√©√© et affiche sa taille
4. Compresse le fichier avec `gzip` (format final : `orchestr-a-backup-YYYYMMDD_HHMMSS.sql.gz`)
5. Supprime les backups de plus de **30 jours** (r√©tention automatique)
6. Affiche le nombre de backups restants

#### V√©rification de l'int√©grit√© du backup

```bash
# V√©rifier qu'un fichier gzip est valide
gzip -t backups/orchestr-a-backup-<DATE>.sql.gz && echo "‚úÖ Archive int√®gre"

# V√©rifier le contenu (lister les premi√®res lignes SQL)
zcat backups/orchestr-a-backup-<DATE>.sql.gz | head -30

# V√©rifier la pr√©sence des tables critiques
zcat backups/orchestr-a-backup-<DATE>.sql.gz | grep "CREATE TABLE" | head -20
```

#### Automatisation par cron

```bash
# √âditer la crontab de l'utilisateur orchestr-a
crontab -e

# Ajouter la ligne suivante (backup quotidien √† 2h du matin) :
0 2 * * * cd /opt/ORCHESTRA && ./scripts/backup-database.sh >> /var/log/orchestr-a-backup.log 2>&1
```

> üí° Les backups sont stock√©s dans `/opt/ORCHESTRA/backups/` et automatiquement purg√©s apr√®s 30 jours par le script.

### 5.3 Backup des fichiers de configuration

```bash
# Script de backup des configurations critiques
BACKUP_CONF="/opt/ORCHESTRA/backups/config-$(date +%Y%m%d_%H%M%S)"
mkdir -p "$BACKUP_CONF"

# Fichiers critiques
cp /opt/ORCHESTRA/.env.production "$BACKUP_CONF/"
cp /opt/ORCHESTRA/docker-compose.prod.yml "$BACKUP_CONF/"
cp /opt/ORCHESTRA/nginx/nginx.conf "$BACKUP_CONF/"

# Archiver
tar czf "$BACKUP_CONF.tar.gz" -C "$(dirname "$BACKUP_CONF")" "$(basename "$BACKUP_CONF")"
rm -rf "$BACKUP_CONF"

echo "‚úÖ Backup config : $BACKUP_CONF.tar.gz"
```

> üî¥ **S√©curit√©** : Le fichier `.env.production` contient des secrets (mots de passe DB/Redis, JWT secret). Stocker le backup de configuration dans un emplacement s√©curis√© avec les permissions appropri√©es (`chmod 600`).

### 5.4 Backup des volumes Docker

#### Volume PostgreSQL (donn√©es critiques)

```bash
# M√©thode recommand√©e : utiliser pg_dump (voir section 5.2)
# Le backup SQL est portable et plus fiable que la copie brute du volume.

# M√©thode alternative : copie brute du volume (arr√™t du container requis)
dc stop postgres
docker run --rm \
  -v orchestr-a-postgres-data-prod:/data:ro \
  -v /opt/ORCHESTRA/backups:/backup \
  alpine tar czf /backup/postgres-volume-$(date +%Y%m%d).tar.gz -C /data .
dc start postgres
```

> üü° La copie brute du volume n√©cessite l'arr√™t de PostgreSQL. Pr√©f√©rer `pg_dump` qui fonctionne √† chaud.

#### Volume Certificats SSL

```bash
docker run --rm \
  -v orchestr-a-certbot-certs:/data:ro \
  -v /opt/ORCHESTRA/backups:/backup \
  alpine tar czf /backup/certbot-certs-$(date +%Y%m%d).tar.gz -C /data .
```

### 5.5 Restauration

#### Restauration de la base de donn√©es seule

‚è±Ô∏è Temps estim√© : 5-15 minutes selon la taille de la base

```bash
cd /opt/ORCHESTRA

# 1. Lister les backups disponibles
ls -lh backups/orchestr-a-backup-*.sql.gz

# 2. Lancer la restauration
./scripts/restore-database.sh backups/orchestr-a-backup-<DATE>.sql.gz
# Le script demande confirmation : taper "oui" pour confirmer
```

Le script `restore-database.sh` :
1. V√©rifie que le fichier de backup existe
2. Demande confirmation (taper `oui` exactement)
3. D√©compresse le `.gz` dans `/tmp/orchestr-a-restore-temp.sql`
4. Injecte le SQL dans PostgreSQL via `psql` dans le container `orchestr-a-postgres-prod`
5. Nettoie le fichier temporaire

> ‚ö†Ô∏è **Cette op√©ration remplace les donn√©es actuelles de la base.** Toutes les modifications faites apr√®s la date du backup seront perdues.

**Apr√®s la restauration :**

```bash
# Red√©marrer l'API pour vider les caches et reconnecter
dc restart api

# V√©rifier que l'application fonctionne
curl -sf http://localhost/api/health && echo " ‚úÖ API OK"
```

#### Restauration compl√®te (disaster recovery)

‚è±Ô∏è Temps estim√© : 1-2 heures

Cette proc√©dure suppose un serveur RHEL 8.10 vierge avec Docker install√©.

```bash
# 1. Installer Docker et les pr√©requis
#    ‚Üí Suivre INSTALL-RHEL8.md sections 1 et 2

# 2. Cloner le projet
git clone https://github.com/ElegAlex/Orchestr-A.git /opt/ORCHESTRA
cd /opt/ORCHESTRA

# 3. Restaurer le fichier .env.production depuis le backup s√©curis√©
cp /chemin/vers/backup/.env.production /opt/ORCHESTRA/.env.production
chmod 600 .env.production

# 4. Restaurer les certificats SSL (si backup disponible)
docker volume create orchestr-a-certbot-certs
docker run --rm \
  -v orchestr-a-certbot-certs:/data \
  -v /chemin/vers/backup:/backup:ro \
  alpine tar xzf /backup/certbot-certs-<DATE>.tar.gz -C /data

# 5. Modifier nginx.conf si le domaine a chang√©
#    ‚Üí Voir section 10.2

# 6. Construire les images
dc build

# 7. D√©marrer la stack
dc up -d

# 8. Attendre que PostgreSQL soit pr√™t
dc logs -f postgres  # Attendre "database system is ready to accept connections"

# 9. Restaurer la base de donn√©es
./scripts/restore-database.sh /chemin/vers/backup/orchestr-a-backup-<DATE>.sql.gz

# 10. Red√©marrer l'API (pour reconnecter apr√®s la restauration)
dc restart api

# 11. V√©rifier
dc ps
curl -sf http://localhost/api/health && echo " ‚úÖ API OK"
curl -sf -o /dev/null http://localhost && echo " ‚úÖ Frontend OK"
```

#### Test de restauration

> üîÑ **Recommandation** : tester la restauration au moins **une fois par trimestre** pour valider la proc√©dure et les backups.

```bash
# Test rapide : v√©rifier l'int√©grit√© du dernier backup
LATEST=$(ls -t backups/orchestr-a-backup-*.sql.gz | head -1)
gzip -t "$LATEST" && echo "‚úÖ Archive int√®gre : $LATEST"
zcat "$LATEST" | grep "CREATE TABLE" | wc -l  # Doit lister les tables attendues
```

---

## 6. S√©curit√© op√©rationnelle

### 6.1 Gestion des secrets

#### Inventaire des secrets

| Secret | Fichier | Usage | Rotation recommand√©e |
|---|---|---|---|
| `DATABASE_PASSWORD` | `.env.production` | Mot de passe PostgreSQL | Annuelle ou apr√®s incident |
| `REDIS_PASSWORD` | `.env.production` | Mot de passe Redis | Annuelle ou apr√®s incident |
| `JWT_SECRET` | `.env.production` | Signature des tokens d'authentification | Annuelle ou apr√®s incident |
| Certificat SSL (cl√© priv√©e) | Volume `orchestr-a-certbot-certs` | Chiffrement HTTPS | Automatique (Let's Encrypt : 90 jours) |
| Mot de passe admin | Base de donn√©es (table `users`) | Acc√®s administrateur applicatif | Trimestrielle |

#### Proc√©dure de rotation du JWT_SECRET

> üî¥ **Impact** : Tous les tokens JWT en cours deviennent invalides. **Tous les utilisateurs connect√©s seront d√©connect√©s** et devront se reconnecter.

‚è±Ô∏è Temps estim√© : 5 minutes | Indisponibilit√© : ~1 minute

```bash
cd /opt/ORCHESTRA

# 1. G√©n√©rer un nouveau secret
NEW_JWT=$(openssl rand -base64 64)
echo "Nouveau JWT_SECRET : $NEW_JWT"

# 2. Sauvegarder le .env actuel
cp .env.production .env.production.backup.$(date +%Y%m%d-%H%M%S)

# 3. Mettre √† jour le JWT_SECRET dans .env.production
#    (√âditer manuellement ou avec sed)
#    Ouvrir le fichier et remplacer la valeur de JWT_SECRET

# 4. Red√©marrer uniquement l'API
dc restart api

# 5. V√©rifier
dc ps
curl -sf http://localhost/api/health && echo " ‚úÖ API OK"
```

#### Proc√©dure de rotation du mot de passe PostgreSQL

> üî¥ **Impact** : L'API ne pourra plus se connecter √† la base tant que le mot de passe n'est pas mis √† jour partout.

‚è±Ô∏è Temps estim√© : 10 minutes | Indisponibilit√© : 2-3 minutes

```bash
cd /opt/ORCHESTRA

# 1. G√©n√©rer un nouveau mot de passe
NEW_DB_PASS=$(openssl rand -base64 48 | tr -dc 'a-zA-Z0-9' | head -c 32)
echo "Nouveau PASSWORD : $NEW_DB_PASS"

# 2. Sauvegarder le .env actuel
cp .env.production .env.production.backup.$(date +%Y%m%d-%H%M%S)

# 3. Changer le mot de passe dans PostgreSQL
docker exec orchestr-a-postgres-prod psql -U postgres -c "ALTER USER postgres PASSWORD '$NEW_DB_PASS';"

# 4. Mettre √† jour DATABASE_PASSWORD dans .env.production
#    √âditer le fichier et remplacer la valeur

# 5. Red√©marrer l'API (pour prendre en compte le nouveau mot de passe)
dc restart api

# 6. V√©rifier la connectivit√©
dc ps
curl -sf http://localhost/api/health && echo " ‚úÖ API OK"
```

#### Proc√©dure de rotation du mot de passe Redis

> üü° **Impact** : L'API perdra temporairement la connexion Redis. Les sessions en cache seront perdues.

‚è±Ô∏è Temps estim√© : 5 minutes | Indisponibilit√© : ~1 minute

```bash
cd /opt/ORCHESTRA

# 1. G√©n√©rer un nouveau mot de passe
NEW_REDIS_PASS=$(openssl rand -base64 48 | tr -dc 'a-zA-Z0-9' | head -c 32)

# 2. Sauvegarder le .env actuel
cp .env.production .env.production.backup.$(date +%Y%m%d-%H%M%S)

# 3. Mettre √† jour REDIS_PASSWORD dans .env.production

# 4. Red√©marrer Redis et l'API
dc down redis api && dc up -d redis api

# 5. V√©rifier
dc ps
curl -sf http://localhost/api/health && echo " ‚úÖ API OK"
```

#### Permissions sur les fichiers sensibles

```bash
# V√©rifier les permissions (√† ex√©cuter p√©riodiquement)
ls -la /opt/ORCHESTRA/.env.production
# Attendu : -rw------- 1 orchestr-a orchestr-a ... .env.production

# Corriger si n√©cessaire
chmod 600 /opt/ORCHESTRA/.env.production
chown orchestr-a:orchestr-a /opt/ORCHESTRA/.env.production

# V√©rifier que .env.production est dans .gitignore
grep ".env.production" /opt/ORCHESTRA/.gitignore
```

### 6.2 Certificats SSL

#### V√©rification de la date d'expiration

```bash
# Via openssl (depuis le serveur)
echo | openssl s_client -connect localhost:443 -servername $(hostname) 2>/dev/null | openssl x509 -noout -dates
# Affiche notBefore et notAfter

# Jours restants avant expiration
EXPIRY=$(echo | openssl s_client -connect localhost:443 2>/dev/null | openssl x509 -noout -enddate | cut -d= -f2)
echo "Expiration : $EXPIRY"
echo "Jours restants : $(( ($(date -d "$EXPIRY" +%s) - $(date +%s)) / 86400 ))"
```

#### Renouvellement automatique

Le container `orchestr-a-certbot-prod` ex√©cute `certbot renew` automatiquement toutes les 12 heures. Aucune action manuelle n'est normalement n√©cessaire.

Pour s'assurer que Nginx recharge le certificat apr√®s renouvellement, ajouter un cron :

```bash
# Recharger Nginx 2 fois par jour (apr√®s le passage de certbot)
0 0,12 * * * docker exec orchestr-a-nginx-prod nginx -s reload > /dev/null 2>&1
```

#### Renouvellement manuel d'urgence

‚è±Ô∏è Temps estim√© : 5 minutes

```bash
# 1. Forcer le renouvellement
docker exec orchestr-a-certbot-prod certbot renew --force-renewal

# 2. Recharger Nginx
docker exec orchestr-a-nginx-prod nginx -s reload

# 3. V√©rifier le nouveau certificat
echo | openssl s_client -connect localhost:443 2>/dev/null | openssl x509 -noout -dates
```

#### Remplacement par un certificat custom (entreprise)

```bash
# 1. Copier les certificats dans le volume certbot
docker run --rm \
  -v orchestr-a-certbot-certs:/certs \
  -v /chemin/vers/certificats:/src:ro \
  alpine sh -c "
    mkdir -p /certs/live/orchestr-a.com &&
    cp /src/fullchain.pem /certs/live/orchestr-a.com/fullchain.pem &&
    cp /src/privkey.pem /certs/live/orchestr-a.com/privkey.pem
  "

# 2. V√©rifier les chemins dans nginx.conf
#    ssl_certificate /etc/nginx/ssl/live/orchestr-a.com/fullchain.pem;
#    ssl_certificate_key /etc/nginx/ssl/live/orchestr-a.com/privkey.pem;
#    Adapter le chemin si le domaine est diff√©rent

# 3. Recharger Nginx
docker exec orchestr-a-nginx-prod nginx -s reload
```

### 6.3 S√©curit√© syst√®me

#### V√©rification SELinux

```bash
# Statut actuel
getenforce
# Attendu : "Enforcing" (recommand√©) ou "Permissive"

# V√©rifier le bool√©en pour les conteneurs
getsebool container_manage_cgroup
# Attendu : container_manage_cgroup --> on

# Si le bool√©en est d√©sactiv√© :
sudo setsebool -P container_manage_cgroup 1

# V√©rifier les alertes SELinux r√©centes
sudo ausearch -m avc -ts recent 2>/dev/null | head -20
```

#### V√©rification firewalld

```bash
# Statut du pare-feu
sudo firewall-cmd --state
# Attendu : "running"

# Lister les services autoris√©s
sudo firewall-cmd --list-all

# V√©rifier que seuls SSH, HTTP et HTTPS sont ouverts
# Attendu : services: ssh http https
# üî¥ Les ports 5432 (PostgreSQL) et 6379 (Redis) ne doivent JAMAIS √™tre expos√©s
```

#### Audit des ports ouverts

```bash
# Ports en √©coute sur le serveur
sudo ss -tlnp

# Attendu :
# :22   ‚Üí sshd
# :80   ‚Üí docker-proxy (Nginx)
# :443  ‚Üí docker-proxy (Nginx)
# Les ports 5432 et 6379 ne doivent appara√Ætre que sur des interfaces Docker internes
```

#### Mise √† jour de s√©curit√© RHEL

üîÑ Fr√©quence recommand√©e : **mensuelle** (ou imm√©diatement pour les CVE critiques)

```bash
# V√©rifier les mises √† jour de s√©curit√© disponibles
sudo dnf check-update --security

# Appliquer les mises √† jour de s√©curit√©
sudo dnf update --security -y

# V√©rifier si un red√©marrage est n√©cessaire
sudo needs-restarting -r
```

### 6.4 Audit et tra√ßabilit√©

#### Logs d'authentification

Les tentatives de connexion (r√©ussies et √©chou√©es) sont enregistr√©es dans les logs de l'API :

```bash
# Rechercher les tentatives de connexion
dc logs api 2>&1 | grep -iE "(login|auth|unauthorized|401)"

# Rechercher les erreurs d'authentification
dc logs api 2>&1 | grep -i "401"
```

#### Logs d'acc√®s Nginx

```bash
# Acc√®s HTTP complets (format personnalis√© avec temps de r√©ponse upstream)
docker exec orchestr-a-nginx-prod cat /var/log/nginx/access.log | tail -50

# Erreurs Nginx
docker exec orchestr-a-nginx-prod cat /var/log/nginx/error.log | tail -50

# Requ√™tes avec code d'erreur 4xx/5xx
docker exec orchestr-a-nginx-prod cat /var/log/nginx/access.log | awk '$9 >= 400'
```

#### Surveillance des tentatives d'intrusion

```bash
# Compter les erreurs 401 (authentification √©chou√©e) par IP
dc logs nginx 2>&1 | grep " 401 " | awk '{print $1}' | sort | uniq -c | sort -rn | head -10

# Compter les erreurs 403 (acc√®s interdit) par IP
dc logs nginx 2>&1 | grep " 403 " | awk '{print $1}' | sort | uniq -c | sort -rn | head -10

# D√©tecter un nombre anormal de requ√™tes par IP (possible DDoS/brute-force)
docker exec orchestr-a-nginx-prod cat /var/log/nginx/access.log | awk '{print $1}' | sort | uniq -c | sort -rn | head -10
```

> üí° Le rate limiting Nginx est configur√© √† **10 requ√™tes/seconde par IP** sur `/api/*` avec un burst de 20 requ√™tes. Cela prot√®ge contre les attaques par brute-force simples.

---

## 7. Monitoring et alerting

### 7.1 M√©triques √† surveiller

| M√©trique | Seuil Warning üü° | Seuil Critique üî¥ | Commande de v√©rification |
|---|---|---|---|
| CPU VM | > 70 % | > 90 % | `top -bn1 \| head -5` |
| RAM VM | < 20 % libre | < 10 % libre | `free -h` |
| Disque VM (`/`) | > 75 % | > 90 % | `df -h /` |
| Espace Docker | > 20 Go | > 40 Go | `docker system df` |
| Containers actifs | < 5 healthy | < 3 healthy | `dc ps` |
| Connexions PostgreSQL | > 80 | > 95 (max 100) | `docker exec orchestr-a-postgres-prod psql -U postgres -c "SELECT count(*) FROM pg_stat_activity;"` |
| M√©moire Redis | > 200 Mo | > 240 Mo (max 256 Mo) | `docker exec orchestr-a-redis-prod redis-cli -a $REDIS_PASSWORD info memory \| grep used_memory_human` |
| Temps de r√©ponse API | > 2 s | > 5 s | `curl -o /dev/null -s -w '%{time_total}' http://localhost/api/health` |
| Certificat SSL | < 30 jours | < 7 jours | Voir section 6.2 |
| Taille logs Nginx | > 500 Mo | > 1 Go | `docker exec orchestr-a-nginx-prod du -sh /var/log/nginx/` |
| Taille backup dir | > 5 Go | > 10 Go | `du -sh /opt/ORCHESTRA/backups/` |

### 7.2 Script de monitoring

Le script `scripts/health-check.sh` fournit une v√©rification de base. Voici un script enrichi pour un monitoring plus complet :

```bash
#!/bin/bash
# monitoring-check.sh ‚Äî Script de monitoring avanc√© pour Orchestr'A
# Usage : ./monitoring-check.sh [--quiet]
# Code retour : 0 = OK, 1 = WARNING, 2 = CRITICAL

QUIET=${1:-""}
WARNINGS=0
CRITICALS=0

check() {
    local name="$1" status="$2" msg="$3"
    if [ "$status" = "CRITICAL" ]; then
        CRITICALS=$((CRITICALS + 1))
        [ -z "$QUIET" ] && echo "üî¥ CRITIQUE : $name ‚Äî $msg"
    elif [ "$status" = "WARNING" ]; then
        WARNINGS=$((WARNINGS + 1))
        [ -z "$QUIET" ] && echo "üü° WARNING  : $name ‚Äî $msg"
    else
        [ -z "$QUIET" ] && echo "üü¢ OK       : $name"
    fi
}

# --- Containers ---
for c in orchestr-a-postgres-prod orchestr-a-redis-prod orchestr-a-api-prod orchestr-a-web-prod orchestr-a-nginx-prod; do
    STATE=$(docker inspect -f '{{.State.Status}}' "$c" 2>/dev/null)
    HEALTH=$(docker inspect -f '{{.State.Health.Status}}' "$c" 2>/dev/null)
    if [ "$STATE" != "running" ]; then
        check "$c" "CRITICAL" "non d√©marr√© (√©tat: $STATE)"
    elif [ -n "$HEALTH" ] && [ "$HEALTH" != "healthy" ]; then
        check "$c" "WARNING" "√©tat sant√©: $HEALTH"
    else
        check "$c"
    fi
done

# --- API sant√© ---
HTTP_CODE=$(curl -sf -o /dev/null -w '%{http_code}' --max-time 10 http://localhost/api/health 2>/dev/null)
if [ "$HTTP_CODE" = "200" ]; then
    check "API endpoint"
else
    check "API endpoint" "CRITICAL" "HTTP $HTTP_CODE"
fi

# --- Espace disque ---
DISK_PCT=$(df / | awk 'NR==2{gsub(/%/,""); print $5}')
if [ "$DISK_PCT" -gt 90 ]; then
    check "Espace disque" "CRITICAL" "${DISK_PCT}% utilis√©"
elif [ "$DISK_PCT" -gt 75 ]; then
    check "Espace disque" "WARNING" "${DISK_PCT}% utilis√©"
else
    check "Espace disque"
fi

# --- RAM ---
MEM_FREE_PCT=$(free | awk '/Mem/{printf "%d", $7/$2*100}')
if [ "$MEM_FREE_PCT" -lt 10 ]; then
    check "M√©moire RAM" "CRITICAL" "${MEM_FREE_PCT}% disponible"
elif [ "$MEM_FREE_PCT" -lt 20 ]; then
    check "M√©moire RAM" "WARNING" "${MEM_FREE_PCT}% disponible"
else
    check "M√©moire RAM"
fi

# --- SSL ---
EXPIRY_DATE=$(echo | openssl s_client -connect localhost:443 2>/dev/null | openssl x509 -noout -enddate 2>/dev/null | cut -d= -f2)
if [ -n "$EXPIRY_DATE" ]; then
    DAYS_LEFT=$(( ($(date -d "$EXPIRY_DATE" +%s) - $(date +%s)) / 86400 ))
    if [ "$DAYS_LEFT" -lt 7 ]; then
        check "Certificat SSL" "CRITICAL" "expire dans ${DAYS_LEFT} jours"
    elif [ "$DAYS_LEFT" -lt 30 ]; then
        check "Certificat SSL" "WARNING" "expire dans ${DAYS_LEFT} jours"
    else
        check "Certificat SSL"
    fi
fi

# --- R√©sum√© ---
echo ""
echo "R√©sum√© : $CRITICALS critique(s), $WARNINGS warning(s)"
[ "$CRITICALS" -gt 0 ] && exit 2
[ "$WARNINGS" -gt 0 ] && exit 1
exit 0
```

#### Int√©gration avec des outils de monitoring

| Outil | Approche d'int√©gration |
|---|---|
| **Prometheus + Grafana** | Exposer les m√©triques via un exporter Node.js dans l'API, ou utiliser `cAdvisor` pour les m√©triques Docker |
| **Zabbix** | Utiliser le script de monitoring comme `UserParameter` dans l'agent Zabbix |
| **Nagios/Icinga** | Adapter le script en plugin Nagios (codes retour : 0=OK, 1=WARNING, 2=CRITICAL) |
| **Uptime Kuma** | Monitorer les URLs `https://<domaine>/api/health` et `https://<domaine>` |

### 7.3 Mise en place d'alertes

#### Health check avec notification email

```bash
# Ajouter dans la crontab (v√©rification toutes les 5 minutes)
*/5 * * * * cd /opt/ORCHESTRA && ./scripts/health-check.sh > /dev/null 2>&1 || echo "ALERTE Orchestr'A : health check en √©chec sur $(hostname) √† $(date)" | mail -s "[ORCHESTR-A] ALERTE SANT√â" admin@example.com
```

#### Alerte sur espace disque

```bash
# V√©rification horaire de l'espace disque
0 * * * * USAGE=$(df / | awk 'NR==2{gsub(/%/,""); print $5}'); [ "$USAGE" -gt 85 ] && echo "ALERTE : Disque √† ${USAGE}% sur $(hostname)" | mail -s "[ORCHESTR-A] Espace disque critique" admin@example.com
```

#### Alerte sur expiration certificat SSL

```bash
# V√©rification quotidienne √† 8h
0 8 * * * DAYS=$(echo | openssl s_client -connect localhost:443 2>/dev/null | openssl x509 -noout -enddate 2>/dev/null | cut -d= -f2 | xargs -I{} bash -c 'echo $(( ($(date -d "{}" +%s) - $(date +%s)) / 86400 ))'); [ -n "$DAYS" ] && [ "$DAYS" -lt 15 ] && echo "ALERTE : Certificat SSL expire dans $DAYS jours sur $(hostname)" | mail -s "[ORCHESTR-A] Certificat SSL bient√¥t expir√©" admin@example.com
```

---

## 8. Fiches r√©flexes incidents

---

### üìã FICHE R√âFLEXE 1 : Application inaccessible (erreur 502/503/504)

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üî¥ **Sympt√¥me** : Les utilisateurs obtiennent une page d'erreur 502 Bad Gateway, 503 Service Unavailable ou 504 Gateway Timeout.

üîç **Diagnostic** :
```bash
# 1. V√©rifier l'√©tat de tous les containers
dc ps

# 2. V√©rifier les logs Nginx
dc logs --tail=30 nginx

# 3. V√©rifier les logs API
dc logs --tail=30 api

# 4. V√©rifier la connectivit√© interne
docker exec orchestr-a-nginx-prod wget -qO- --timeout=5 http://api:4000/api/health
docker exec orchestr-a-nginx-prod wget -qO- --timeout=5 http://web:3000
```

üõ†Ô∏è **R√©solution** :

1. **Si l'API est arr√™t√©e** :
   ```bash
   dc restart api
   dc logs -f api  # Attendre "listening on port 4000"
   ```
2. **Si le Web est arr√™t√©** :
   ```bash
   dc restart web
   ```
3. **Si Nginx est arr√™t√©** :
   ```bash
   docker exec orchestr-a-nginx-prod nginx -t  # Tester la config
   dc restart nginx
   ```
4. **Si tous les services sont arr√™t√©s** :
   ```bash
   dc down && dc up -d
   ```

‚úÖ **V√©rification** :
```bash
curl -sf http://localhost/api/health && echo "‚úÖ API OK"
curl -sf -o /dev/null http://localhost && echo "‚úÖ Frontend OK"
```

‚è±Ô∏è **Temps estim√©** : 2-5 minutes

üîÑ **Pr√©vention** : La politique `restart: unless-stopped` red√©marre automatiquement les containers. Mettre en place le monitoring (section 7) pour √™tre alert√© avant que les utilisateurs ne le signalent.

---

### üìã FICHE R√âFLEXE 2 : Container en restart loop

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üî¥ **Sympt√¥me** : Un container red√©marre en boucle. `dc ps` affiche `Restarting` ou un uptime tr√®s court.

üîç **Diagnostic** :
```bash
# 1. Identifier le container en boucle
dc ps  # Rep√©rer le container avec un uptime de quelques secondes

# 2. Lire les logs pour comprendre la cause du crash
dc logs --tail=100 <service>

# 3. V√©rifier les √©v√©nements Docker
docker events --since="10m" --filter container=<container_name>
```

üõ†Ô∏è **R√©solution** :

1. **Erreur de configuration** (variable manquante dans `.env.production`) :
   ```bash
   # V√©rifier les variables requises
   grep -E "^(DATABASE_PASSWORD|REDIS_PASSWORD|JWT_SECRET)=" .env.production
   ```
2. **D√©pendance non disponible** (ex: API d√©marre avant que PostgreSQL soit pr√™t) :
   ```bash
   # Red√©marrer dans l'ordre
   dc down && dc up -d
   ```
3. **M√©moire insuffisante** :
   ```bash
   free -h
   docker stats --no-stream
   ```
4. **Image corrompue** :
   ```bash
   dc down
   dc build --no-cache <service>
   dc up -d
   ```

‚úÖ **V√©rification** : `dc ps` ‚Äî le container doit rester `Up` pendant au moins 2 minutes.

‚è±Ô∏è **Temps estim√©** : 5-15 minutes

üîÑ **Pr√©vention** : Surveiller les logs r√©guli√®rement. La configuration `deploy.restart_policy` de l'API limite les red√©marrages √† 3 tentatives avec un intervalle de 5 secondes.

---

### üìã FICHE R√âFLEXE 3 : Base de donn√©es inaccessible

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üî¥ **Sympt√¥me** : L'API retourne des erreurs de connexion √† la base de donn√©es. Logs mentionnant `ECONNREFUSED`, `connection refused`, ou `could not connect to server`.

üîç **Diagnostic** :
```bash
# 1. V√©rifier l'√©tat du container PostgreSQL
docker inspect orchestr-a-postgres-prod --format '{{.State.Status}} / {{.State.Health.Status}}'

# 2. V√©rifier que PostgreSQL accepte les connexions
docker exec orchestr-a-postgres-prod pg_isready -U postgres -d orchestr_a_prod

# 3. V√©rifier les logs PostgreSQL
dc logs --tail=50 postgres

# 4. V√©rifier l'espace disque du volume
docker exec orchestr-a-postgres-prod df -h /var/lib/postgresql/data
```

üõ†Ô∏è **R√©solution** :

1. **Container arr√™t√©** :
   ```bash
   dc start postgres
   # Attendre le health check (10 secondes)
   sleep 15 && dc restart api
   ```
2. **Espace disque plein** ‚Üí voir Fiche r√©flexe 5
3. **Trop de connexions** :
   ```bash
   # V√©rifier les connexions actives
   docker exec orchestr-a-postgres-prod psql -U postgres -c "SELECT count(*) FROM pg_stat_activity;"
   # Tuer les connexions inactives
   docker exec orchestr-a-postgres-prod psql -U postgres -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE state = 'idle' AND pid <> pg_backend_pid();"
   ```
4. **Mot de passe incorrect** (apr√®s rotation) :
   ```bash
   # V√©rifier DATABASE_PASSWORD dans .env.production
   grep DATABASE_PASSWORD .env.production
   # Red√©marrer la stack pour recharger la configuration
   dc down && dc up -d
   ```

‚úÖ **V√©rification** :
```bash
docker exec orchestr-a-postgres-prod pg_isready -U postgres && echo "‚úÖ PostgreSQL OK"
curl -sf http://localhost/api/health && echo "‚úÖ API connect√©e"
```

‚è±Ô∏è **Temps estim√©** : 5-15 minutes

üîÑ **Pr√©vention** : Monitorer les connexions actives et l'espace disque. Configurer les alertes (section 7.3).

---

### üìã FICHE R√âFLEXE 4 : Redis indisponible

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üî¥ **Sympt√¥me** : Lenteurs applicatives, sessions utilisateur perdues, logs API mentionnant `ECONNREFUSED` sur le port 6379.

üîç **Diagnostic** :
```bash
# 1. V√©rifier l'√©tat du container
docker inspect orchestr-a-redis-prod --format '{{.State.Status}} / {{.State.Health.Status}}'

# 2. Tester la connexion Redis
docker exec orchestr-a-redis-prod redis-cli -a "$REDIS_PASSWORD" ping

# 3. V√©rifier la m√©moire Redis
docker exec orchestr-a-redis-prod redis-cli -a "$REDIS_PASSWORD" info memory | grep used_memory_human

# 4. Logs Redis
dc logs --tail=30 redis
```

üõ†Ô∏è **R√©solution** :

1. **Container arr√™t√©** :
   ```bash
   dc start redis
   sleep 10 && dc restart api  # Reconnecter l'API
   ```
2. **M√©moire pleine** (maxmemory 256 Mo atteint) :
   ```bash
   # La politique allkeys-lru devrait g√©rer l'√©viction automatiquement
   # Si probl√®me persistant, flush le cache (les sessions seront perdues)
   docker exec orchestr-a-redis-prod redis-cli -a "$REDIS_PASSWORD" FLUSHALL
   ```
3. **Mot de passe incorrect** :
   ```bash
   grep REDIS_PASSWORD .env.production
   dc down redis api && dc up -d redis api
   ```

‚úÖ **V√©rification** :
```bash
docker exec orchestr-a-redis-prod redis-cli -a "$REDIS_PASSWORD" ping
# Attendu : PONG
```

‚è±Ô∏è **Temps estim√©** : 2-5 minutes

üîÑ **Pr√©vention** : L'impact de la perte de Redis est limit√© (d√©connexion des sessions, pas de perte de donn√©es m√©tier). La politique `allkeys-lru` √©vite automatiquement le d√©passement m√©moire en supprimant les cl√©s les moins r√©cemment utilis√©es.

---

### üìã FICHE R√âFLEXE 5 : Espace disque plein

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üî¥ **Sympt√¥me** : Erreurs d'√©criture, containers qui crashent, PostgreSQL qui refuse les transactions, `No space left on device` dans les logs.

üîç **Diagnostic** :
```bash
# 1. Espace disque global
df -h /

# 2. Utilisation Docker d√©taill√©e
docker system df -v

# 3. Plus gros r√©pertoires
sudo du -sh /var/lib/docker/* | sort -rh | head -10

# 4. Taille des backups
du -sh /opt/ORCHESTRA/backups/
```

üõ†Ô∏è **R√©solution** :

1. **Nettoyage Docker imm√©diat** (gain : souvent plusieurs Go) :
   ```bash
   # Supprimer les images non utilis√©es, containers arr√™t√©s, caches de build
   docker system prune -f
   
   # Si insuffisant, supprimer aussi les images non taggu√©es
   docker image prune -a -f
   ```
2. **Nettoyage des anciens backups** :
   ```bash
   # Supprimer les backups de plus de 7 jours (en urgence)
   find /opt/ORCHESTRA/backups/ -name "*.sql.gz" -mtime +7 -delete
   ```
3. **Rotation forc√©e des logs Docker** :
   ```bash
   # Les logs sont d√©j√† limit√©s par la config Docker, mais si besoin :
   sudo truncate -s 0 $(docker inspect --format='{{.LogPath}}' orchestr-a-nginx-prod)
   ```

‚úÖ **V√©rification** :
```bash
df -h /  # Doit montrer < 80% d'utilisation
dc ps    # Tous les services doivent √™tre healthy
```

‚è±Ô∏è **Temps estim√©** : 5-15 minutes

üîÑ **Pr√©vention** : Configurer l'alerte espace disque (section 7.3). Planifier le nettoyage Docker mensuel (section 9.2).

---

### üìã FICHE R√âFLEXE 6 : Certificat SSL expir√©

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üî¥ **Sympt√¥me** : Les navigateurs affichent une erreur de certificat. `NET::ERR_CERT_DATE_INVALID` ou similaire.

üîç **Diagnostic** :
```bash
# V√©rifier la date d'expiration
echo | openssl s_client -connect localhost:443 2>/dev/null | openssl x509 -noout -dates

# V√©rifier l'√©tat du container certbot
docker inspect orchestr-a-certbot-prod --format '{{.State.Status}}'

# Logs certbot
dc logs --tail=30 certbot
```

üõ†Ô∏è **R√©solution** :

```bash
# 1. Forcer le renouvellement
docker exec orchestr-a-certbot-prod certbot renew --force-renewal

# 2. Si le certbot ne fonctionne pas, renouveler manuellement
dc stop nginx certbot
docker run --rm \
  -v orchestr-a-certbot-certs:/etc/letsencrypt \
  -v orchestr-a-certbot-www:/var/www/certbot \
  -p 80:80 \
  certbot/certbot certonly --standalone -d <votre-domaine> --agree-tos --email admin@<votre-domaine> --non-interactive
dc start nginx certbot

# 3. Recharger Nginx
docker exec orchestr-a-nginx-prod nginx -s reload
```

‚úÖ **V√©rification** :
```bash
echo | openssl s_client -connect localhost:443 2>/dev/null | openssl x509 -noout -dates
# notAfter doit √™tre dans ~90 jours
```

‚è±Ô∏è **Temps estim√©** : 5-10 minutes

üîÑ **Pr√©vention** : Le container certbot renouvelle automatiquement. Configurer l'alerte d'expiration (section 7.3). Ajouter le cron de reload Nginx (section 6.2).

---

### üìã FICHE R√âFLEXE 7 : Performances d√©grad√©es (lenteurs)

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üî¥ **Sympt√¥me** : L'application est lente, les pages mettent plus de 5 secondes √† charger, les requ√™tes API timeout.

üîç **Diagnostic** :
```bash
# 1. Charge syst√®me
uptime    # Load average
free -h   # RAM
df -h /   # Disque

# 2. Consommation des containers
docker stats --no-stream

# 3. Temps de r√©ponse API
curl -o /dev/null -s -w 'DNS: %{time_namelookup}s | Connect: %{time_connect}s | Total: %{time_total}s\n' http://localhost/api/health

# 4. Connexions PostgreSQL
docker exec orchestr-a-postgres-prod psql -U postgres -c "SELECT count(*), state FROM pg_stat_activity GROUP BY state;"

# 5. Requ√™tes longues en cours
docker exec orchestr-a-postgres-prod psql -U postgres -c "SELECT pid, now() - pg_stat_activity.query_start AS duration, query FROM pg_stat_activity WHERE state = 'active' AND (now() - pg_stat_activity.query_start) > interval '5 seconds';"

# 6. Redis latence
docker exec orchestr-a-redis-prod redis-cli -a "$REDIS_PASSWORD" --latency-history -i 1
```

üõ†Ô∏è **R√©solution** :

1. **CPU/RAM satur√©** : identifier le process responsable avec `docker stats`, envisager un scaling vertical (plus de ressources VM)
2. **Requ√™tes SQL lentes** :
   ```bash
   # Tuer les requ√™tes longues (> 60 secondes)
   docker exec orchestr-a-postgres-prod psql -U postgres -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE state = 'active' AND (now() - query_start) > interval '60 seconds' AND pid <> pg_backend_pid();"
   ```
3. **Redis satur√©** :
   ```bash
   docker exec orchestr-a-redis-prod redis-cli -a "$REDIS_PASSWORD" FLUSHALL
   dc restart api
   ```
4. **Trop de connexions** : red√©marrer l'API pour lib√©rer les connexions
   ```bash
   dc restart api
   ```

‚úÖ **V√©rification** :
```bash
curl -o /dev/null -s -w '%{time_total}s\n' http://localhost/api/health
# Attendu : < 1 seconde
```

‚è±Ô∏è **Temps estim√©** : 10-30 minutes (diagnostic inclus)

üîÑ **Pr√©vention** : Maintenance PostgreSQL r√©guli√®re (VACUUM/ANALYZE ‚Äî section 9.3). Monitoring proactif des m√©triques de performance.

---

### üìã FICHE R√âFLEXE 8 : Erreur de migration Prisma au d√©marrage

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üî¥ **Sympt√¥me** : L'API ne d√©marre pas. Les logs montrent `prisma migrate deploy` en √©chec, `P3009`, `Migration failed to apply` ou similaire.

üîç **Diagnostic** :
```bash
# 1. Lire les logs complets de l'API
dc logs api

# 2. V√©rifier l'√©tat des migrations
docker exec orchestr-a-api-prod npx prisma migrate status

# 3. V√©rifier la connectivit√© √† la base
docker exec orchestr-a-postgres-prod pg_isready -U postgres
```

üõ†Ô∏è **R√©solution** :

1. **Migration √©chou√©e √† mi-chemin** :
   ```bash
   # Marquer la migration √©chou√©e comme appliqu√©e (si le sch√©ma est correct manuellement)
   docker exec orchestr-a-api-prod npx prisma migrate resolve --applied <nom_migration>
   
   # Red√©marrer l'API
   dc restart api
   ```
2. **Migration incompatible avec les donn√©es existantes** :
   ```bash
   # Restaurer le backup et revenir au code pr√©c√©dent
   ./scripts/restore-database.sh backups/orchestr-a-backup-<DATE>.sql.gz
   git checkout <commit_precedent>
   dc build api && dc restart api
   ```

> üî¥ **Ne JAMAIS ex√©cuter `prisma migrate reset` en production** ‚Äî cela supprime TOUTES les donn√©es.

‚úÖ **V√©rification** :
```bash
dc ps  # L'API doit √™tre healthy
docker exec orchestr-a-api-prod npx prisma migrate status  # Toutes les migrations appliqu√©es
```

‚è±Ô∏è **Temps estim√©** : 15-30 minutes

üîÑ **Pr√©vention** : Toujours effectuer un backup avant mise √† jour. Tester les migrations en environnement de staging avant la production.

---

### üìã FICHE R√âFLEXE 9 : Perte de connexion entre API et base de donn√©es

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üî¥ **Sympt√¥me** : L'API fonctionne mais les requ√™tes √©chouent avec des erreurs 500. Logs : `Connection terminated unexpectedly`, `Connection pool timeout`.

üîç **Diagnostic** :
```bash
# 1. V√©rifier que PostgreSQL est accessible depuis le container API
docker exec orchestr-a-api-prod sh -c 'nc -zv postgres 5432'

# 2. V√©rifier le r√©seau Docker
docker network inspect orchestr-a-network-prod

# 3. V√©rifier les connexions PostgreSQL
docker exec orchestr-a-postgres-prod psql -U postgres -c "SELECT count(*), state FROM pg_stat_activity GROUP BY state;"
```

üõ†Ô∏è **R√©solution** :

1. **Probl√®me r√©seau Docker** :
   ```bash
   # Recr√©er le r√©seau (n√©cessite un red√©marrage complet)
   dc down && dc up -d
   ```
2. **Pool de connexions √©puis√©** :
   ```bash
   dc restart api  # R√©initialise le pool de connexions Prisma
   ```
3. **PostgreSQL a √©t√© red√©marr√©** (connexions existantes devenues invalides) :
   ```bash
   dc restart api
   ```

‚úÖ **V√©rification** :
```bash
curl -sf http://localhost/api/health && echo "‚úÖ Connexion DB OK"
```

‚è±Ô∏è **Temps estim√©** : 2-10 minutes

üîÑ **Pr√©vention** : La reconnexion automatique est g√©r√©e par Prisma, mais un red√©marrage de l'API peut √™tre n√©cessaire si le pool est dans un √©tat incoh√©rent.

---

### üìã FICHE R√âFLEXE 10 : Corruption de donn√©es suspect√©e

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üî¥ **Sympt√¥me** : Donn√©es incoh√©rentes dans l'application, valeurs manquantes ou incorrectes, erreurs d'int√©grit√© r√©f√©rentielle.

üîç **Diagnostic** :
```bash
# 1. V√©rifier l'int√©grit√© des tables principales
docker exec orchestr-a-postgres-prod psql -U postgres -d orchestr_a_prod -c "
SELECT schemaname, relname, n_live_tup FROM pg_stat_user_tables ORDER BY n_live_tup DESC;
"

# 2. V√©rifier les contraintes d'int√©grit√©
docker exec orchestr-a-postgres-prod psql -U postgres -d orchestr_a_prod -c "
SELECT conname, conrelid::regclass FROM pg_constraint WHERE contype = 'f' AND NOT convalidated;
"

# 3. Lancer un FULL VACUUM pour d√©tecter les corruptions
docker exec orchestr-a-postgres-prod psql -U postgres -d orchestr_a_prod -c "VACUUM FULL VERBOSE;"
```

üõ†Ô∏è **R√©solution** :

1. **Corruption l√©g√®re** (donn√©es incoh√©rentes mais tables intactes) :
   - Corriger manuellement via des requ√™tes SQL cibl√©es
   - Documenter les corrections effectu√©es

2. **Corruption grave** (tables endommag√©es) :
   ```bash
   # Restaurer depuis le dernier backup valide
   ./scripts/restore-database.sh backups/orchestr-a-backup-<DATE>.sql.gz
   dc restart api
   ```

> ‚ö†Ô∏è **Avant toute restauration**, effectuer un backup de l'√©tat actuel (m√™me corrompu) pour analyse ult√©rieure :
> ```bash
> docker exec orchestr-a-postgres-prod pg_dump -U postgres orchestr_a_prod | gzip > backups/pre-restore-$(date +%Y%m%d_%H%M%S).sql.gz
> ```

‚úÖ **V√©rification** : Se connecter √† l'application et v√©rifier les donn√©es via l'interface.

‚è±Ô∏è **Temps estim√©** : 30 minutes √† 2 heures selon la gravit√©

üîÑ **Pr√©vention** : Backups quotidiens. Maintenance PostgreSQL r√©guli√®re (VACUUM ‚Äî section 9.3). Ne jamais tuer le container PostgreSQL brutalement (`docker kill`).

---

### üìã FICHE R√âFLEXE 11 : Attaque suspect√©e / tentatives d'intrusion

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üî¥ **Sympt√¥me** : Nombre anormal de requ√™tes, tentatives de connexion √©chou√©es massives, trafic inhabituel, alertes de rate limiting.

üîç **Diagnostic** :
```bash
# 1. Analyser les logs d'acc√®s Nginx
docker exec orchestr-a-nginx-prod cat /var/log/nginx/access.log | awk '{print $1}' | sort | uniq -c | sort -rn | head -20

# 2. Requ√™tes suspectes (injections SQL, traversal, etc.)
docker exec orchestr-a-nginx-prod grep -iE "(union|select|drop|insert|delete|update|script|alert|\.\.\/)" /var/log/nginx/access.log | tail -20

# 3. Tentatives de brute-force sur /api/auth/login
dc logs api 2>&1 | grep -i "401" | tail -50

# 4. V√©rifier le rate limiting
docker exec orchestr-a-nginx-prod cat /var/log/nginx/error.log | grep "limiting" | tail -20
```

üõ†Ô∏è **R√©solution** :

1. **Bloquer une IP suspecte** (via firewalld) :
   ```bash
   # Bloquer une IP sp√©cifique
   sudo firewall-cmd --permanent --add-rich-rule='rule family="ipv4" source address="<IP_SUSPECTE>" reject'
   sudo firewall-cmd --reload
   ```
2. **V√©rifier qu'aucun compte n'a √©t√© compromis** :
   ```bash
   # Lister les derni√®res connexions r√©ussies
   dc logs api 2>&1 | grep -i "login.*success" | tail -20
   ```
3. **Changer les secrets par pr√©caution** (voir section 6.1) :
   - Rotation du `JWT_SECRET` (d√©connecte tous les utilisateurs)
   - Changer le mot de passe admin
4. **Escalader** au niveau N3/N4 si l'attaque est confirm√©e

‚úÖ **V√©rification** : Surveiller les logs pendant les heures suivantes pour confirmer que l'attaque a cess√©.

‚è±Ô∏è **Temps estim√©** : 15-60 minutes (investigation + rem√©diation)

üîÑ **Pr√©vention** : Le rate limiting Nginx (10 req/s par IP) limite les attaques par brute-force. Maintenir le pare-feu √† jour. Appliquer les patches de s√©curit√© RHEL.

---

### üìã FICHE R√âFLEXE 12 : Panne compl√®te de la VM (PRA)

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üî¥ **Sympt√¥me** : La VM est inaccessible (crash mat√©riel, panne hyperviseur, incident datacenter).

üîç **Diagnostic** : V√©rifier avec l'h√©bergeur/√©quipe infrastructure l'√©tat de la VM et les perspectives de r√©cup√©ration.

üõ†Ô∏è **R√©solution** :

**Cas 1 : La VM peut √™tre restaur√©e (donn√©es intactes)**
```bash
# 1. Red√©marrer la VM
# 2. V√©rifier Docker
sudo systemctl start docker
sudo systemctl status docker

# 3. Red√©marrer la stack
cd /opt/ORCHESTRA && dc up -d

# 4. V√©rifier
dc ps
curl -sf http://localhost/api/health
```

**Cas 2 : La VM est perdue (disaster recovery sur nouveau serveur)**

Suivre la proc√©dure de restauration compl√®te (section 5.5) :
1. Provisionner une nouvelle VM RHEL 8.10
2. Installer Docker (cf. `INSTALL-RHEL8.md` sections 1-2)
3. Cloner le projet depuis GitHub
4. Restaurer `.env.production` depuis le backup s√©curis√©
5. Restaurer les certificats SSL
6. Construire et d√©marrer
7. Restaurer la base de donn√©es depuis le dernier backup
8. Mettre √† jour le DNS pour pointer vers la nouvelle IP
9. V√©rifier le fonctionnement complet

> üî¥ **Pr√©requis critiques pour le PRA** :
> - Backup de la base de donn√©es stock√© **hors du serveur** (stockage externe, NAS, cloud)
> - Backup du fichier `.env.production` stock√© **hors du serveur**
> - Acc√®s au d√©p√¥t Git (GitHub) depuis le nouveau serveur

‚úÖ **V√©rification** : Parcourir la checklist fonctionnelle compl√®te (voir `INSTALL-RHEL8.md` section 7).

‚è±Ô∏è **Temps estim√©** : 1-4 heures selon la disponibilit√© des backups et de l'infrastructure

üîÑ **Pr√©vention** :
- Externaliser les backups (ne pas stocker uniquement sur la VM)
- Tester le PRA **au moins une fois par an** (id√©alement trimestriel)
- Documenter les contacts h√©bergeur et les proc√©dures de provisioning VM

---

## 9. Maintenance pr√©ventive

### 9.1 Planning de maintenance

| Fr√©quence | T√¢che | Proc√©dure | Criticit√© |
|---|---|---|---|
| **Quotidien** | V√©rification sant√© des containers | Section 3.3 ‚Äî Checklist quotidienne | üî¥ Critique |
| **Quotidien** | Contr√¥le des logs d'erreurs | Section 3.2 ‚Äî `dc logs --since=24h api 2>&1 \| grep -i error` | üü° Important |
| **Quotidien** | V√©rification du backup automatique | `ls -lt backups/ \| head -2` | üî¥ Critique |
| **Hebdomadaire** | V√©rification espace disque | `df -h / && docker system df` | üü° Important |
| **Hebdomadaire** | V√©rification int√©grit√© backup | `gzip -t $(ls -t backups/*.sql.gz \| head -1)` | üü° Important |
| **Hebdomadaire** | Contr√¥le certificat SSL | Section 6.2 ‚Äî V√©rification expiration | üü° Important |
| **Mensuel** | Mises √† jour s√©curit√© RHEL | Section 4.3 ‚Äî `sudo dnf update --security` | üî¥ Critique |
| **Mensuel** | Nettoyage Docker | Section 9.2 | üü¢ Recommand√© |
| **Mensuel** | Maintenance PostgreSQL (VACUUM) | Section 9.3 | üü° Important |
| **Mensuel** | V√©rification m√©moire Redis | Section 9.4 | üü¢ Recommand√© |
| **Mensuel** | Rotation/v√©rification des logs | Section 3.2 (automatique via Docker) | üü¢ Recommand√© |
| **Trimestriel** | Test de restauration backup | Section 5.5 ‚Äî Test restauration | üî¥ Critique |
| **Trimestriel** | Revue des acc√®s utilisateurs | Audit des comptes dans l'application | üü° Important |
| **Trimestriel** | Rotation du mot de passe admin | Section 3.4 | üü° Important |
| **Annuel** | Rotation des secrets (JWT, DB, Redis) | Section 6.1 | üü° Important |
| **Annuel** | Test PRA complet | Section 5.5 ‚Äî Disaster recovery | üî¥ Critique |
| **Annuel** | Revue d'architecture et dimensionnement | Section 10.3 | üü¢ Recommand√© |

### 9.2 Nettoyage Docker

‚è±Ô∏è Temps estim√© : 2-5 minutes | Aucune indisponibilit√©

#### √âvaluer l'espace r√©cup√©rable

```bash
# Vue d'ensemble de l'utilisation Docker
docker system df

# Vue d√©taill√©e
docker system df -v
```

#### Nettoyage s√©curis√©

```bash
# 1. Supprimer les containers arr√™t√©s
docker container prune -f

# 2. Supprimer les images non utilis√©es (anciennes versions)
docker image prune -f

# 3. Supprimer le cache de build
docker builder prune -f

# 4. Nettoyage complet (containers arr√™t√©s + images non utilis√©es + r√©seaux non utilis√©s)
docker system prune -f
```

> üî¥ **Pr√©cautions** :
> - **Ne JAMAIS utiliser** `docker system prune -a --volumes` ‚Äî cela supprimerait les volumes de donn√©es (PostgreSQL, Redis)
> - `docker system prune -f` (sans `-a`) est s√ªr : il ne supprime que les √©l√©ments orphelins
> - Toujours v√©rifier avec `dc ps` que les containers sont en cours d'ex√©cution avant le nettoyage

#### Estimation de l'espace r√©cup√©rable typique

| √âl√©ment | Espace typique | Commande |
|---|---|---|
| Images non taggu√©es | 1-5 Go | `docker image prune -f` |
| Cache de build | 2-10 Go | `docker builder prune -f` |
| Containers arr√™t√©s | < 100 Mo | `docker container prune -f` |

### 9.3 Maintenance PostgreSQL

#### VACUUM et ANALYZE

PostgreSQL maintient un m√©canisme d'autovacuum qui fonctionne automatiquement. Cependant, un VACUUM manuel p√©riodique est recommand√© pour les tables √† fort taux de modification :

```bash
# VACUUM ANALYZE ‚Äî r√©cup√®re l'espace et met √† jour les statistiques
# (Ne bloque PAS les requ√™tes, ex√©cutable en production)
docker exec orchestr-a-postgres-prod psql -U postgres -d orchestr_a_prod -c "VACUUM ANALYZE;"
```

> üí° `VACUUM ANALYZE` est une op√©ration non bloquante qui peut √™tre ex√©cut√©e √† tout moment. `VACUUM FULL` (qui r√©cup√®re plus d'espace) **bloque les tables** et ne doit √™tre ex√©cut√© qu'en maintenance.

```bash
# VACUUM FULL ‚Äî √† n'ex√©cuter qu'en fen√™tre de maintenance (bloque les tables)
docker exec orchestr-a-postgres-prod psql -U postgres -d orchestr_a_prod -c "VACUUM FULL VERBOSE;"
```

#### V√©rification de la taille de la base

```bash
# Taille totale de la base
docker exec orchestr-a-postgres-prod psql -U postgres -c "
SELECT pg_database.datname, pg_size_pretty(pg_database_size(pg_database.datname)) AS size
FROM pg_database WHERE datname = 'orchestr_a_prod';
"

# Taille par table (top 10)
docker exec orchestr-a-postgres-prod psql -U postgres -d orchestr_a_prod -c "
SELECT relname AS table, pg_size_pretty(pg_total_relation_size(relid)) AS total_size
FROM pg_catalog.pg_statio_user_tables
ORDER BY pg_total_relation_size(relid) DESC
LIMIT 10;
"
```

#### Surveillance des connexions

```bash
# Connexions actives par √©tat
docker exec orchestr-a-postgres-prod psql -U postgres -c "
SELECT state, count(*) FROM pg_stat_activity WHERE datname = 'orchestr_a_prod' GROUP BY state;
"

# Connexion maximale configur√©e
docker exec orchestr-a-postgres-prod psql -U postgres -c "SHOW max_connections;"
# Par d√©faut : 100
```

### 9.4 Maintenance Redis

#### V√©rification m√©moire utilis√©e

```bash
# M√©moire utilis√©e
docker exec orchestr-a-redis-prod redis-cli -a "$REDIS_PASSWORD" info memory | grep -E "used_memory_human|maxmemory_human|maxmemory_policy"

# Nombre de cl√©s
docker exec orchestr-a-redis-prod redis-cli -a "$REDIS_PASSWORD" dbsize
```

> üí° Redis est configur√© avec `maxmemory 256mb` et la politique `allkeys-lru` qui √©victe automatiquement les cl√©s les moins r√©cemment utilis√©es quand la limite est atteinte.

#### Flush du cache

> ‚ö†Ô∏è **Impact** : Toutes les sessions utilisateur seront perdues. Les utilisateurs devront se reconnecter.

```bash
# Vider compl√®tement Redis
docker exec orchestr-a-redis-prod redis-cli -a "$REDIS_PASSWORD" FLUSHALL

# V√©rifier
docker exec orchestr-a-redis-prod redis-cli -a "$REDIS_PASSWORD" dbsize
# Attendu : (integer) 0
```

---

## 10. Proc√©dures exceptionnelles

### 10.1 Migration vers un nouveau serveur

‚è±Ô∏è Temps estim√© : 2-4 heures | Indisponibilit√© : 1-2 heures

#### üìã Checklist pr√©-migration

- [ ] Nouveau serveur RHEL 8.10 provisionn√© et accessible en SSH
- [ ] Docker CE install√© sur le nouveau serveur (cf. `INSTALL-RHEL8.md`)
- [ ] Acc√®s r√©seau depuis le nouveau serveur (GitHub, Let's Encrypt)
- [ ] Backup frais de la base de donn√©es
- [ ] Copie s√©curis√©e du `.env.production`
- [ ] DNS TTL r√©duit (300 secondes) au moins 24h avant la migration

#### Proc√©dure

**Sur l'ancien serveur :**

```bash
cd /opt/ORCHESTRA

# 1. Cr√©er un backup frais
./scripts/backup-database.sh

# 2. Copier les fichiers critiques vers le nouveau serveur
scp .env.production user@nouveau-serveur:/tmp/
scp backups/$(ls -t backups/ | head -1) user@nouveau-serveur:/tmp/

# 3. Backup des certificats SSL
docker run --rm \
  -v orchestr-a-certbot-certs:/data:ro \
  -v /tmp:/backup \
  alpine tar czf /backup/certbot-certs-migration.tar.gz -C /data .
scp /tmp/certbot-certs-migration.tar.gz user@nouveau-serveur:/tmp/
```

**Sur le nouveau serveur :**

```bash
# 4. Cloner le projet
git clone https://github.com/ElegAlex/Orchestr-A.git /opt/ORCHESTRA
cd /opt/ORCHESTRA

# 5. Restaurer la configuration
cp /tmp/.env.production .
chmod 600 .env.production

# 6. Restaurer les certificats SSL
docker volume create orchestr-a-certbot-certs
docker run --rm \
  -v orchestr-a-certbot-certs:/data \
  -v /tmp:/backup:ro \
  alpine tar xzf /backup/certbot-certs-migration.tar.gz -C /data

# 7. Construire les images
dc build

# 8. D√©marrer la stack
dc up -d

# 9. Attendre que PostgreSQL soit pr√™t
sleep 30 && dc ps

# 10. Copier le backup dans le r√©pertoire de backups
mkdir -p backups && cp /tmp/orchestr-a-backup-*.sql.gz backups/

# 11. Restaurer la base de donn√©es
./scripts/restore-database.sh backups/$(ls -t backups/ | head -1)

# 12. Red√©marrer l'API
dc restart api

# 13. V√©rifier
dc ps
curl -sf http://localhost/api/health && echo "‚úÖ API OK"
curl -sf -o /dev/null http://localhost && echo "‚úÖ Frontend OK"
```

**Basculement DNS :**

```bash
# 14. Mettre √† jour l'enregistrement DNS pour pointer vers la nouvelle IP
# 15. Attendre la propagation DNS (v√©rifier avec : dig +short <domaine>)

# 16. Sur l'ancien serveur ‚Äî arr√™ter les services
ssh user@ancien-serveur "cd /opt/ORCHESTRA && dc down"
```

#### üìã Checklist post-migration

- [ ] Application accessible via le domaine
- [ ] Certificat SSL valide
- [ ] Connexion admin fonctionnelle
- [ ] Donn√©es pr√©sentes et coh√©rentes
- [ ] Backup cron configur√© sur le nouveau serveur
- [ ] Monitoring configur√©
- [ ] Ancien serveur arr√™t√© (conserver 7 jours avant suppression)

### 10.2 Changement de nom de domaine

‚è±Ô∏è Temps estim√© : 30-60 minutes | Indisponibilit√© : 10-15 minutes

**Impact** : Nginx, CORS, SSL, variables d'environnement.

```bash
cd /opt/ORCHESTRA
NEW_DOMAIN="nouveau-domaine.example.com"
```

**1. Mettre √† jour la configuration Nginx**

√âditer `nginx/nginx.conf` et remplacer toutes les occurrences de l'ancien domaine :
- `server_name` (2 blocs : HTTP et HTTPS)
- Chemins SSL : `/etc/nginx/ssl/live/<domaine>/`

```bash
# V√©rifier les occurrences √† modifier
grep -n "orchestr-a.com" nginx/nginx.conf
```

**2. Mettre √† jour `.env.production`**

```bash
# Modifier CORS_ORIGIN avec le nouveau domaine
# CORS_ORIGIN=https://nouveau-domaine.example.com
```

**3. Obtenir un nouveau certificat SSL**

```bash
dc stop nginx certbot

docker run --rm \
  -v orchestr-a-certbot-certs:/etc/letsencrypt \
  -v orchestr-a-certbot-www:/var/www/certbot \
  -p 80:80 \
  certbot/certbot certonly --standalone -d "$NEW_DOMAIN" --agree-tos --email "admin@$NEW_DOMAIN" --non-interactive
```

**4. Reconstruire et red√©marrer**

```bash
# Le frontend doit √™tre reconstruit si NEXT_PUBLIC_API_URL change
dc build web
dc up -d

# V√©rifier
dc ps
```

**5. Mettre √† jour le DNS**

Cr√©er un enregistrement A (ou CNAME) pointant `$NEW_DOMAIN` vers l'IP du serveur.

### 10.3 Mont√©e en charge

#### Indicateurs de saturation

| Indicateur | Seuil de saturation | Action |
|---|---|---|
| CPU VM > 80 % en continu | Saturation compute | Augmenter les vCPU |
| RAM VM < 10 % libre en continu | Saturation m√©moire | Augmenter la RAM |
| Connexions PG > 80 / 100 | Saturation DB | Augmenter `max_connections` ou optimiser les requ√™tes |
| Redis > 240 Mo / 256 Mo | Saturation cache | Augmenter `maxmemory` |
| Disque > 80 % | Saturation stockage | Ajouter de l'espace disque |
| Temps r√©ponse API > 3 s | D√©gradation UX | Investiguer (DB, code, infra) |

#### Options de scaling vertical

L'architecture actuelle (Docker Compose sur un serveur unique) se pr√™te au **scaling vertical** :

```bash
# Augmenter les limites de ressources dans docker-compose.prod.yml
# Modifier les sections deploy.resources.limits pour chaque service

# Apr√®s modification :
dc down && dc up -d
```

| Ressource | Minimum recommand√© | Pour 50 utilisateurs | Pour 200 utilisateurs |
|---|---|---|---|
| vCPU | 2 | 4 | 8 |
| RAM | 4 Go | 8 Go | 16 Go |
| Disque | 20 Go | 50 Go | 100 Go |

#### Limites connues de l'architecture actuelle

| Contrainte | Limite approximative | Solution si d√©pass√©e |
|---|---|---|
| Serveur unique | Pas de haute disponibilit√© | Mise en place d'un cluster (hors p√©rim√®tre) |
| PostgreSQL unique | ~500 connexions simultan√©es | Ajouter PgBouncer (pool de connexions) |
| Redis unique | 256 Mo cache | Augmenter `maxmemory` dans docker-compose |
| Pas de CDN | Latence pour les utilisateurs distants | Ajouter un CDN (Cloudflare, etc.) |
| Pas de load balancer | Pas de r√©partition de charge | N√©cessite une refonte d'architecture |

---

## 11. Annexes

### A. Commandes Docker ‚Äî Aide-m√©moire

> üí° Alias recommand√© : `alias dc='docker compose --env-file .env.production -f docker-compose.prod.yml'`

#### Gestion des services

```bash
# D√©marrer tous les services
dc up -d

# Arr√™ter tous les services
dc down

# Red√©marrer un service
dc restart <service>        # api, web, postgres, redis, nginx, certbot

# Voir l'√©tat des services
dc ps

# Reconstruire un service
dc build <service>
dc build --no-cache <service>  # Sans cache
```

#### Logs

```bash
# Logs en temps r√©el
dc logs -f                  # Tous les services
dc logs -f <service>        # Un service sp√©cifique
dc logs --tail=100 <service>  # Derni√®res 100 lignes
dc logs --since=1h <service>  # Depuis 1 heure
```

#### Inspection

```bash
# Entrer dans un container (shell interactif)
docker exec -it orchestr-a-api-prod sh
docker exec -it orchestr-a-postgres-prod psql -U postgres -d orchestr_a_prod
docker exec -it orchestr-a-redis-prod redis-cli -a "$REDIS_PASSWORD"

# Informations sur un container
docker inspect orchestr-a-api-prod
docker inspect orchestr-a-api-prod --format '{{.State.Status}}'

# Ressources utilis√©es
docker stats --no-stream
```

#### Maintenance

```bash
# Nettoyage
docker system prune -f           # Containers arr√™t√©s + images + r√©seaux orphelins
docker image prune -f            # Images non utilis√©es
docker builder prune -f          # Cache de build

# Volumes
docker volume ls                 # Lister les volumes
docker volume inspect <volume>   # D√©tails d'un volume

# R√©seau
docker network ls
docker network inspect orchestr-a-network-prod
```

### B. R√©capitulatif des ports et flux

| Port | Protocole | Service | Direction | R√®gle firewall |
|---|---|---|---|---|
| 22 | TCP | SSH | Entr√©e | `firewall-cmd --add-service=ssh` |
| 80 | TCP | Nginx (HTTP ‚Üí redirect HTTPS) | Entr√©e | `firewall-cmd --add-service=http` |
| 443 | TCP | Nginx (HTTPS) | Entr√©e | `firewall-cmd --add-service=https` |
| 4000 | TCP | API NestJS | Interne Docker uniquement | üî¥ Ne PAS exposer |
| 3000 | TCP | Web Next.js | Interne Docker uniquement | üî¥ Ne PAS exposer |
| 5432 | TCP | PostgreSQL | Interne Docker uniquement | üî¥ Ne JAMAIS exposer |
| 6379 | TCP | Redis | Interne Docker uniquement | üî¥ Ne JAMAIS exposer |

### C. R√©capitulatif des volumes et donn√©es persistantes

| Volume Docker | Contenu | Taille estim√©e | Backup n√©cessaire | Criticit√© |
|---|---|---|---|---|
| `orchestr-a-postgres-data-prod` | Donn√©es PostgreSQL | 100 Mo ‚Äì 10 Go | ‚úÖ Oui (via `pg_dump`) | üî¥ Critique |
| `orchestr-a-redis-data-prod` | Donn√©es Redis (AOF) | 10 ‚Äì 256 Mo | ‚ùå Non (cache reconstruit) | üü¢ Faible |
| `orchestr-a-api-logs-prod` | Logs applicatifs API | 10 ‚Äì 250 Mo | ‚ùå Non (diagnostic) | üü¢ Faible |
| `orchestr-a-nginx-logs-prod` | Logs Nginx (access + error) | 10 ‚Äì 100 Mo | ‚ùå Non (diagnostic) | üü¢ Faible |
| `orchestr-a-certbot-certs` | Certificats SSL Let's Encrypt | < 10 Mo | ‚úÖ Oui (mensuel) | üü° Important |
| `orchestr-a-certbot-www` | Fichiers ACME challenge | < 1 Mo | ‚ùå Non (temporaire) | üü¢ N√©gligeable |

### D. R√©capitulatif des fichiers de configuration

| Fichier | R√¥le | Modifiable en exploitation | Red√©marrage requis |
|---|---|---|---|
| `.env.production` | Secrets et param√®tres d'environnement | üü° Oui (avec pr√©caution) | Oui ‚Äî `dc down && dc up -d` |
| `docker-compose.prod.yml` | D√©finition des services Docker | üî¥ Non (sauf limites ressources) | Oui ‚Äî `dc down && dc up -d` |
| `nginx/nginx.conf` | Reverse proxy, SSL, rate limiting | üü° Oui (tester avec `nginx -t`) | Oui ‚Äî `dc restart nginx` |
| `apps/api/Dockerfile` | Build de l'image API | ‚ùå Non en exploitation | Rebuild ‚Äî `dc build api` |
| `apps/web/Dockerfile` | Build de l'image Web | ‚ùå Non en exploitation | Rebuild ‚Äî `dc build web` |
| `infrastructure/docker/postgres/init.sql` | Init PostgreSQL (1√®re ex√©cution) | ‚ùå Non pertinent apr√®s install | N/A |
| `packages/database/prisma/schema.prisma` | Sch√©ma de base de donn√©es | üî¥ Jamais en production | Migration requise |

### E. Crontab de production recommand√©e

```bash
# =============================================================================
# Crontab de production ‚Äî Orchestr'A V2
# Installation : crontab -e (en tant qu'utilisateur orchestr-a)
# =============================================================================

# Alias de commande Docker Compose
DC="docker compose --env-file /opt/ORCHESTRA/.env.production -f /opt/ORCHESTRA/docker-compose.prod.yml"

# --- Sauvegarde quotidienne (2h du matin) ---
0 2 * * * cd /opt/ORCHESTRA && ./scripts/backup-database.sh >> /var/log/orchestr-a-backup.log 2>&1

# --- Health check toutes les 5 minutes ---
*/5 * * * * cd /opt/ORCHESTRA && ./scripts/health-check.sh > /dev/null 2>&1 || echo "ALERTE Orchestr'A : health check en √©chec sur $(hostname) √† $(date)" | mail -s "[ORCHESTR-A] ALERTE SANT√â" admin@example.com

# --- Recharger Nginx apr√®s renouvellement certbot (2 fois par jour) ---
0 0,12 * * * docker exec orchestr-a-nginx-prod nginx -s reload > /dev/null 2>&1

# --- Alerte espace disque (toutes les heures) ---
0 * * * * USAGE=$(df / | awk 'NR==2{gsub(/%/,""); print $5}'); [ "$USAGE" -gt 85 ] && echo "ALERTE : Disque √† ${USAGE}% sur $(hostname)" | mail -s "[ORCHESTR-A] Espace disque" admin@example.com

# --- Alerte certificat SSL (quotidien √† 8h) ---
0 8 * * * DAYS=$(echo | openssl s_client -connect localhost:443 2>/dev/null | openssl x509 -noout -enddate 2>/dev/null | cut -d= -f2 | xargs -I{} bash -c 'echo $(( ($(date -d "{}" +%s) - $(date +%s)) / 86400 ))'); [ -n "$DAYS" ] && [ "$DAYS" -lt 15 ] && echo "ALERTE : Certificat SSL expire dans $DAYS jours" | mail -s "[ORCHESTR-A] SSL bient√¥t expir√©" admin@example.com

# --- Nettoyage Docker mensuel (1er dimanche du mois √† 3h) ---
0 3 1-7 * 0 docker system prune -f >> /var/log/orchestr-a-docker-cleanup.log 2>&1

# --- VACUUM PostgreSQL mensuel (1er dimanche du mois √† 4h) ---
0 4 1-7 * 0 docker exec orchestr-a-postgres-prod psql -U postgres -d orchestr_a_prod -c "VACUUM ANALYZE;" >> /var/log/orchestr-a-vacuum.log 2>&1
```

> ‚ö†Ô∏è Remplacer `admin@example.com` par l'adresse email r√©elle de l'√©quipe d'exploitation.
> üí° Pour que les alertes email fonctionnent, un agent de messagerie (ex: `postfix`, `mailx`) doit √™tre install√© sur le serveur.

### F. Templates de communication

#### Template ‚Äî Maintenance planifi√©e

```
Objet : [ORCHESTR'A] Maintenance planifi√©e ‚Äî <DATE> de <HEURE_D√âBUT> √† <HEURE_FIN>

Bonjour,

Une maintenance planifi√©e de l'application Orchestr'A est programm√©e :

üìÖ Date : <DATE>
‚è∞ Horaire : de <HEURE_D√âBUT> √† <HEURE_FIN>
‚è±Ô∏è Dur√©e estim√©e : <DUR√âE>
üîß Nature : <DESCRIPTION> (mise √† jour applicative / maintenance infrastructure / etc.)

üí° Impact : L'application sera indisponible pendant la dur√©e de l'intervention.
Les donn√©es saisies avant la maintenance seront conserv√©es.

üìã Actions requises : Veuillez sauvegarder votre travail en cours avant <HEURE_D√âBUT>.

En cas de prolongation, un message compl√©mentaire sera envoy√©.

Cordialement,
L'√©quipe d'exploitation
```

#### Template ‚Äî Incident en cours

```
Objet : [ORCHESTR'A] üî¥ INCIDENT EN COURS ‚Äî <DESCRIPTION_COURTE>

Bonjour,

Un incident est actuellement en cours sur l'application Orchestr'A :

üî¥ Statut : INCIDENT EN COURS
üìÖ D√©tect√© le : <DATE> √† <HEURE>
üîç Sympt√¥me : <DESCRIPTION DU SYMPT√îME> (application inaccessible / lenteurs / erreurs)
üë• Impact : <NOMBRE> utilisateurs potentiellement impact√©s
üõ†Ô∏è Action : L'√©quipe d'exploitation est mobilis√©e pour r√©soudre l'incident.

‚è∞ Prochaine communication pr√©vue : <HEURE> (ou d√®s r√©solution)

Cordialement,
L'√©quipe d'exploitation
```

#### Template ‚Äî R√©solution d'incident

```
Objet : [ORCHESTR'A] ‚úÖ INCIDENT R√âSOLU ‚Äî <DESCRIPTION_COURTE>

Bonjour,

L'incident signal√© est d√©sormais r√©solu :

‚úÖ Statut : R√âSOLU
üìÖ D√©but : <DATE_D√âBUT> √† <HEURE_D√âBUT>
üìÖ Fin : <DATE_FIN> √† <HEURE_FIN>
‚è±Ô∏è Dur√©e totale : <DUR√âE>
üîç Cause : <DESCRIPTION DE LA CAUSE RACINE>
üõ†Ô∏è R√©solution : <DESCRIPTION DE LA R√âSOLUTION>
üîÑ Actions pr√©ventives : <MESURES POUR √âVITER LA R√âCURRENCE>

L'application est √† nouveau pleinement op√©rationnelle.
N'h√©sitez pas √† signaler tout comportement anormal.

Cordialement,
L'√©quipe d'exploitation
```

---

*Document g√©n√©r√© le 2026-02-06. Pour l'installation initiale, consulter `INSTALL-RHEL8.md`.*
